{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5021e016-b2ef-4532-b2cf-2f7c1d7563e5",
   "metadata": {},
   "source": [
    "TODO: Set up an exclusive alpha map; so it has to choose between alphas for multi prompts on a single image. For example, a region that has \"jean luc picard\" cannot be the same as a region that has \"emma watson\". If we want we could relax or play with those constraints; but let's keep it simple first. We want to eventualy build a map of the whole image with all classes that way.\n",
    "\n",
    "To do that, add loss penalizing common alpha (dot product between offending alpha masks)\n",
    "\n",
    "If total alpha dips below some threshold, or some kinda statistic - it means it failed to find the thing\n",
    "\n",
    "To combine masks, we can have another optimization that allows weighted averages of all previously found masks until we get one we like.\n",
    "\n",
    "TODO: Average the results across multiple runs. What can we do with that? \n",
    "\n",
    "TODO: Add some kinda priors for shape; like superpixels or something. Instance segmentation can kinda do this, so can bilaterl blurs...\n",
    "\n",
    "TODO: Multiple classes - use stabledifusion prompt subtraction\n",
    "\n",
    "TODO: Get mean prompt across texts\n",
    "\n",
    "Ways to think about it:\n",
    "- What can we chip away while keeping the given prompt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ec7b35-00c7-4ec8-beb3-205a09d1f5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rp\n",
    "import nerf.sd as sd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from ryan.source.learnable_textures import LearnableTexturePackRaster,LearnableTexturePackFourier\n",
    "from ryan.source.learnable_textures import LearnableImageRaster,LearnableImageFourier, LearnableImageRasterBilateral, LearnableImageFourierBilateral\n",
    "import icecream\n",
    "from IPython.display import clear_output\n",
    "from ryan.bilateral_blur import BilateralProxyBlur\n",
    "import timm\n",
    "from torchvision.transforms.functional import normalize\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "from timm.models.vision_transformer import vit_base_patch16_224_dino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3ad4a1-e8b2-4db6-ba6e-cb4da32fb97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 's' not in dir():\n",
    "    s=sd.StableDiffusion('cuda:1',\"CompVis/stable-diffusion-v1-4\")\n",
    "    # s=sd.StableDiffusion('cuda:1',\"/raid/xiangli/Codes/VOC-model/motorbike-colorful-g-ext\")\n",
    "    # s=sd.StableDiffusion('cuda:1',\"/raid/xiangli/Codes/VOC-model/dog-colorful-randp2\")\n",
    "device=s.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82ae188-d1b7-49e8-a76d-b38fcd2679a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SETTINGS\n",
    "def make_learnable_image(height, width, num_channels, foreground=None):\n",
    "    #Here we determine our image parametrization schema\n",
    "    bilateral_blur =  BilateralProxyBlur(foreground,**bilateral_kwargs)\n",
    "    return LearnableImageFourierBilateral(bilateral_blur,num_channels) #A neural neural image\n",
    "    return LearnableImageRasterBilateral(bilateral_blur,num_channels) #A neural neural image\n",
    "    return LearnableImageFourier(height,width,num_channels) #A neural neural image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747f66e9-c2f3-463f-bb21-7010b80ecbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_embedding(prompts:list):\n",
    "    return torch.mean(\n",
    "        torch.stack(\n",
    "            [s.get_text_embeddings(prompt) for prompt in prompts]\n",
    "        ),\n",
    "        dim=0\n",
    "    ).to(device)\n",
    "\n",
    "class BaseLabel:\n",
    "    def __init__(self, name:str, embedding:torch.Tensor):\n",
    "        #Later on we might have more sophisticated embeddings, such as averaging multiple prompts\n",
    "        #We also might have associated colors for visualization, or relations between labels\n",
    "        self.name=name\n",
    "        self.embedding=embedding\n",
    "        \n",
    "    def get_sample_image(self):\n",
    "        output=s.embeddings_to_imgs(self.embedding)[0]\n",
    "        assert rp.is_image(output)\n",
    "        return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '%s(name=%s)'%(type(self).__name__,self.name)\n",
    "        \n",
    "class SimpleLabel(BaseLabel):\n",
    "    def __init__(self, name:str):\n",
    "        super().__init__(name, s.get_text_embeddings(name).to(device))\n",
    "\n",
    "class MeanLabel(BaseLabel):\n",
    "    #Test: rp.display_image(rp.horizontally_concatenated_images(MeanLabel('Dogcat','dog','cat').get_sample_image() for _ in range(1)))\n",
    "    def __init__(self, name:str, *prompts):\n",
    "        prompts=rp.detuple(prompts)\n",
    "        super().__init__(name, get_mean_embedding(prompts))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61d0b22-9146-4105-bc81-f67226aaa79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder='stable_diffusion_samples'\n",
    "\n",
    "prompts='''\n",
    "Jean Luc Picard\n",
    "Beverly Crusher\n",
    "Jean Luc Picard and Beverly Crusher\n",
    "Harry Styles\n",
    "Emma Watson\n",
    "Emma Watson and Harry Styles\n",
    "Arnold Schwarzenegger\n",
    "Danny Devito\n",
    "Arnold Schwarzenegger and Danny Devito\n",
    "Harry Potter\n",
    "Hermoine Granger\n",
    "Harry Potter and Hermoine Granger\n",
    "Chimchar\n",
    "Turtwig\n",
    "Piplup\n",
    "Chimchar and Turtwig and Piplup\n",
    "Creeper\n",
    "Minecraft Creeper\n",
    "Minecraft Steve\n",
    "Minecraft Steve and Creeper\n",
    "Rintaroi Okabe Anime Boy\n",
    "Makise Kurisu Anime Girl\n",
    "Rintaroi Okabe Anime Boy from Steins Gate\n",
    "Makise Kurisu Anime Girl from Steins Gate\n",
    "Makise Kurisu Anime Girl and Rintaroi Okabe Anime Boy\n",
    "Makise Kurisu Anime Girl and Rintaroi Okabe Anime Boy from Steins Gate\n",
    "'''.strip().splitlines()\n",
    "\n",
    "while True:\n",
    "    for prompt in prompts:\n",
    "        file_name=prompt+('_%05i'%(rp.millis()%10000))+'.png'\n",
    "        image=SimpleLabel(prompt).get_sample_image()\n",
    "        out_path=rp.path_join(output_folder,file_name)\n",
    "\n",
    "        from IPython.display import clear_output\n",
    "        clear_output()\n",
    "        print(out_path)\n",
    "        rp.display_image(image)\n",
    "        rp.save_image(image,rp.path_join(output_folder,file_name))\n",
    "        print('saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f67663f-be20-4d19-8858-2a6be3a17c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea34c47-6519-41fc-88f9-3d59bdbf797f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
