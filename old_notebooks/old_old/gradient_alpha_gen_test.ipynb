{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87aff688-f4d5-4742-8c66-6ed270838e93",
   "metadata": {},
   "source": [
    "Improvements:\n",
    "\n",
    "Because this is all about blending; it can probably be done completely in latent space. This might make it faster and more detailed maybe?\n",
    "\n",
    "Use a loss to push down the alpha values - we want them small.\n",
    "\n",
    "If we use non-random timesteps can we get larger diversity?\n",
    "\n",
    "Make the loss more straightfoward - using the decoder. This should improve image quality even when using raster!\n",
    "\n",
    "Do a grid of backgrounds + foregrounds (disentanble them all at once)\n",
    "\n",
    "This can all be done during the 3d process as well - though it appears we proably don't have to??\n",
    "\n",
    "3 way compositions:\n",
    "X Y in Z where X<{jesus, kermit, obama} and Y<{driving a car, eating a sandwich, shooting a gun} in {heaven, hell, australia}\n",
    "\n",
    "Investigate: Why does this work without the greenscreen prompt suffixes?\n",
    "\n",
    "Allow movement/zooming via weighted averages of small changes in posisition - between steps, we don't apply the weighted average - instead we apply the average weighted translation \n",
    "\n",
    "Neat tricks: an image that looks good at any hue (randomize hue shift during optimization...or maybe during regular diffusion who knows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ec7b35-00c7-4ec8-beb3-205a09d1f5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rp\n",
    "\n",
    "import nerf.sd as sd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from source.learnable_textures import LearnableTexturePackRaster,LearnableTexturePackFourier\n",
    "from source.learnable_textures import LearnableImageRaster,LearnableImageFourier\n",
    "import icecream\n",
    "from diffusers import AutoencoderKL, UNet2DConditionModel, PNDMScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3ad4a1-e8b2-4db6-ba6e-cb4da32fb97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 's' not in dir():\n",
    "    s=sd.StableDiffusion('cuda:2')\n",
    "    # s=sd.StableDiffusion('cuda:0','nitrosocke/Arcane-Diffusion')\n",
    "device=s.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5617ce2-566f-4967-9063-4ae3e77f6c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts=[\n",
    "    # 'arcane style, jinx wearing goggles', \n",
    "    # 'beautiful sks hatsune miku, Greg Rutkowski, ilya kuvshinov,artgerm highly detailed',\n",
    "    # 'arcane style, beautiful sks hatsune miku, ilya kuvshinov,artgerm highly detailed',\n",
    "    # 'arcane style, beautiful sks gay rainbow dragon, ilya kuvshinov,artgerm highly detailed',\n",
    "    # 'arcane style, dragon',\n",
    "    # 'arcane style, shitting his cranberries, jean luc picard of the starship enterprise, in a sea of cranberries',\n",
    "    # 'arcane style, shrek shrek shrek shrek shrek shrek',\n",
    "    # 'arcane style, korra from legend of korra',\n",
    "    # 'arcane style, emma watson holding a puppy',\n",
    "    'arcane style, sonic the hedgehog',\n",
    "    # \"arcane style, hatsune miku\",\n",
    "    # \"arcane style, a puppy with two heads\",\n",
    "    # \"arcane style, a cylon\",\n",
    "    # \"kurokiyousei hatsune miku\",\n",
    "    # \"hatsune miku\",\n",
    "    # \"shrek\"\n",
    "]*3\n",
    "\n",
    "try:\n",
    "    for prompt in prompts:\n",
    "        image = s.prompt_to_img(prompt)[0]\n",
    "        with rp.SetCurrentDirectoryTemporarily(rp.make_directory('untracked/image_dump')):\n",
    "            print('Saved:',\n",
    "                  rp.save_image(image,\n",
    "                                '%s__%i'%(prompt, rp.millis())\n",
    "                               )\n",
    "                 )\n",
    "        rp.display_image(image)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Cancelled\")\n",
    "    pass\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6049e454-d398-4367-8ade-7673aee34778",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorBlendedLearnableImage(nn.Module):\n",
    "    def __init__(self,image,color=(0,0,0),learnable_image=None):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # if isinstance(image,str):\n",
    "            # S=256\n",
    "            # image=rp.load_image(image,use_cache=True)\n",
    "            # image=rp.cv_resize_image(image,(S,S))\n",
    "        \n",
    "        # assert rp.is_image(image)\n",
    "        assert len(color)==3\n",
    "        # image=rp.as_rgb_image(rp.as_float_image(image))\n",
    "        height=width=512\n",
    "        # height=width=256\n",
    "        # height=width=128\n",
    "        r,g,b=color\n",
    "        \n",
    "        # self.foreground=rp.as_torch_image(image).to(device)\n",
    "        # self.foreground=LearnableImageFourier(256,256).to(device)\n",
    "        \n",
    "        if learnable_image is None:\n",
    "            self.learnable_image=LearnableImageFourier(height,width,num_channels=4,num_features=512).to(device)#RGBA\n",
    "            # self.learnable_alpha=LearnableImageRaster(height,width,num_channels=1)\n",
    "        else:\n",
    "            self.learnable_image=learnable_image\n",
    "        \n",
    "        self.background=torch.zeros(3,height,width,dtype=torch.float32).to(device)\n",
    "        self.background[0]=r\n",
    "        self.background[1]=g\n",
    "        self.background[2]=b\n",
    "    \n",
    "    def forward(self):\n",
    "        im=self.learnable_image()\n",
    "        \n",
    "        \n",
    "        alpha=im[3:,:,:,]\n",
    "        # alpha=alpha.clamp(0,1)\n",
    "        \n",
    "        foreground=im[:3,:,:]\n",
    "        # foreground=foreground.mean(0,keepdim=True).repeat(3,1,1)#Grayscale it!\n",
    "\n",
    "        output=foreground*alpha + (1-alpha) * self.background\n",
    "        return output\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01e0985-0ea0-4049-925e-df9bfadb7735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cartridge: Custom\n",
    "image_url=\"https://upload.wikimedia.org/wikipedia/en/7/7d/Lenna_%28test_image%29.png\"\n",
    "\n",
    "X='a woman wearing a tall beige hat with purple feathers'\n",
    "X='hatsune miku as a mouse'\n",
    "X='a magical surreal cottage'\n",
    "X='a photograph of a human skull'\n",
    "# X='a cyberpunk assassin girl'\n",
    "# X='an award winning makeup tutorial'\n",
    "X='the tree of life'\n",
    "X=\"a 3d kawaii cyberpunk girl's face\"\n",
    "X=\"cyberpunk lolita outfit\"\n",
    "X='a 3d steampunk cat head made of brass gears and bolts, trending on artstation'\n",
    "X='a spectacular photo of a nuclear blast mushroom cloud, trending on artstation'#Failed once\n",
    "X='A staircase to heaven, long tall twisting. Beautiful spiral staircase into the clouds, into the gates of heaven. Trending on artstation, unreal engine'\n",
    "X=\"cupcake themed lolita outfit. a beautiful lolita dress with accessories. kawaii lolita dress. cure lolita outfit.\"\n",
    "X=\"a cute kitten in a cardboard box. Trending on artstation, unreal engine\"\n",
    "# X='a photograph of a puppy'\n",
    "X='a photograph of a teddy bear eating a baguette'\n",
    "X='a photograph of a teddy bear wielding a giant flaming claymore'\n",
    "X='a photograph of a teddy bear wielding a giant sword and shield'\n",
    "X='a photograph of a dog in a mecha suit. a mecha doge!'\n",
    "X='a photograph of a spooky skeleton doing a jojo pose'\n",
    "X='a photograph of two skeletons kissing'\n",
    "X='a gay rainbow dragon, 3d unreal engine trending on artstation'\n",
    "X='complex metal truss scaffolding bridge, 3d unreal engine trending on artstation'\n",
    "X='complex rusty metal truss scaffolding radio tower, 3d unreal engine trending on artstation'\n",
    "X='anime, 3d character design, wild hot east asian woman, ghibli studio, big beautiful eyes, black skirt, tinted glasses, cool, attitude, bershka, teki, cinematic lighting, hyperreal octane render, bape, emo, black shirt, supreme, detailed, hd, 4k'\n",
    "X='3d character design , rainbow hair , long hair , wild hot woman, ghibli studio, symbols tattoos on body, partly in armor, blue tinted glasses , cool, attitude, techwear , teki, bape, supreme, detailed, hd, 4k'\n",
    "X='a big sailboat, hypermaximalistic, high details, cinematic, 8k resolution, beautiful detailed, insanely intricate details, artstation trending, octane render, unreal engine'\n",
    "X='beautiful young russian female model, boudoir, red and black formal business suit, sensual, studio lighting, trending on instagram, full body, detailed and intricate, super detailed artstation scifi scene an old ward,one  ceiling fan, wheelchair, crutches,bed, dust, paneled walls,window,summer unreal engine 5, hyper realism, realistic shading, cinematic composition, blender render, octane render, hdr, detailed textures, photorealistic, wide shot portrait of a spanish conquistador in battle, by Daniel Zrom, masamune shirow, josan gonzales and dan mumford, ayami kojima, takato yamamoto, barclay shaw, karol bak, yukito kishiro scifi  advanced mushroom city streets, modern architecture, by Michael Parkes, concept art powerful male clown, willem dafoe as the joker, full body character concept, covered in full metal armor, art nouveau, super powers, fantasy, intricate, elegant, highly detailed, digital painting, artstation, concept art, shining, sharp focus, illustration, art oleg bulakh the world war i, surrealistic detailed claymation art, dark, moody, foggy '\n",
    "X='concept art for a car with saw blades on the sides, illustrated by syd mead, high quality'\n",
    "X='a low poly tree with cubes as fruits'\n",
    "# X='Minecraft House Ideas on blank canvas, beautiful bright lighting, god rays, bloom effect with volumetric lighting, trending on artstation, artstation RTX, artstation graphic'\n",
    "# X='planet saturn lithograph by adolphe millot'\n",
    "# X='picture of Flat universe and 3D Planet popping out with galaxy and star background'\n",
    "X='three identical planet earths arranged at 9 0 degrees from each other, realistic photograph'\n",
    "X='Danny devito'\n",
    "X='violin'\n",
    "X='helicopter'\n",
    "X='a flying pig wearing aviator goggles, barreling torwards the camera with a smile on its face. A pig flying torwards the camera wearing flight goggles'\n",
    "X='a metallic silver dalek'\n",
    "X='portrait Anime Boy in mechanical armor steampunk cute-fine-face, pretty face, realistic shaded Perfect face, fine details. Anime. Bioshock steampunk realistic shaded lighting by katsuhiro otomo ghost-in-the-shell, magali villeneuve, artgerm, rutkowski Jeremy Lipkin and Giuseppe Dangelico Pino and Michael Garmash and Rob Re'\n",
    "X='Sushi'\n",
    "X='Hamburger'\n",
    "X='A wooden wheelbarrow full of cabbages'\n",
    "X='A wooden wheelbarrow full of puppies'\n",
    "X='Cotton candy ice cream cone'\n",
    "X='a hamburger made of gravel and mud'\n",
    "X='shrek'\n",
    "X='pikachu'\n",
    "X='Hollow knight'\n",
    "X='mario'\n",
    "X='the tree of life'\n",
    "X='arcane style, jinx wearing goggles'\n",
    "X='arcane style, jinx '\n",
    "X='arcane style, dragon'\n",
    "X='arcane style, emma watson holding a puppy'\n",
    "\n",
    "\n",
    "\n",
    "# X='two spooky skeletons kissing'\n",
    "# X='emma watson kissing a skeleton'\n",
    "\n",
    "# X='an award winning photo of jesus eating an avocado'\n",
    "# X='an avocado armchair'\n",
    "# X='saturn and neptune'\n",
    "# X='a close-up photo of the planet saturn'\n",
    "\n",
    "text_black=s.get_text_embeddings('X in deep space. A X clip art, on a black background'.replace('X',X))\n",
    "text_white=s.get_text_embeddings('X clip art with bright light. X on a white background'.replace('X',X))\n",
    "\n",
    "# text_red  =s.get_text_embeddings('a photograph of a X on a solid red background'.replace('X',X))\n",
    "# text_green=s.get_text_embeddings('a photograph of a X on a solid green background'.replace('X',X))\n",
    "# text_blue =s.get_text_embeddings('a X on a solid blue background'.replace('X',X))\n",
    "\n",
    "text_red  =s.get_text_embeddings('X on a red screen, stock image. royalty free picture of X on a solid red background.'.replace('X',X))\n",
    "text_gree =s.get_text_embeddings('X on a green screen, stock image. royalty free picture of X on a solid green background.'.replace('X',X))\n",
    "text_blue =s.get_text_embeddings('X on a blue screen, stock image. royalty free picture of X on a solid blue background.'.replace('X',X))\n",
    "\n",
    "text_blue=text_red=text_green=text_white=text_black=s.get_text_embeddings('X'.replace('X',X))#Do the prompts even matter?\n",
    "\n",
    "\n",
    "\n",
    "def do_display(skip=1,img_only=False):\n",
    "    ds_imgs=[]\n",
    "    ds_imgs.append(rp.as_numpy_image(image_black()))\n",
    "    ds_imgs.append(rp.as_numpy_image(image_white()))\n",
    "    ds_imgs.append(rp.as_numpy_image(image_red  ()))\n",
    "    ds_imgs.append(rp.as_numpy_image(image_green()))\n",
    "    ds_imgs.append(rp.as_numpy_image(image_blue ()))\n",
    "    ds_imgs.append(rp.as_numpy_image(image_alpha()))\n",
    "    ds_imgs.append(rp.as_numpy_image(image_full ()))\n",
    "    ds_imgs=rp.labeled_images(ds_imgs,['On black','On white','On red','On green','On blue','Alpha','RGB w/o Alpha'])\n",
    "    dsimg=rp.horizontally_concatenated_images(ds_imgs)\n",
    "    dsimg=rp.labeled_image(dsimg,X,size=20)\n",
    "    rp.display_image(dsimg)\n",
    "    \n",
    "\n",
    "    # rp.line_graph_via_bokeh([x.var() for x  in ds_black])\n",
    "    # rp.line_graph_via_bokeh([x.mean() for x  in ds_black])\n",
    "\n",
    "    icecream.ic(len(ds_black),X)\n",
    "    if not img_only:\n",
    "        rp.display_image_slideshow([rp.labeled_image(rp.horizontally_concatenated_images(imgs),i*skip*SKIP) for i,imgs in enumerate(zip(ds_black[::skip],ds_white[::skip],alphas[::skip],fulls[::skip]))])\n",
    "        \n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f14fee3-f6fc-46f3-a01c-0be8b73cd637",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_black=ColorBlendedLearnableImage(image_url,(0,0,0),learnable_image=None                       ).to(s.device)\n",
    "image_white=ColorBlendedLearnableImage(image_url,(1,1,1),learnable_image=image_black.learnable_image).to(s.device)\n",
    "image_red  =ColorBlendedLearnableImage(image_url,(1,0,0),learnable_image=image_black.learnable_image).to(s.device)\n",
    "image_green=ColorBlendedLearnableImage(image_url,(0,1,0),learnable_image=image_black.learnable_image).to(s.device)\n",
    "image_blue =ColorBlendedLearnableImage(image_url,(0,0,1),learnable_image=image_black.learnable_image).to(s.device)\n",
    "\n",
    "def image_alpha():\n",
    "    return rp.as_numpy_array(image_black.learnable_image()[3])\n",
    "\n",
    "def image_full():\n",
    "    return rp.as_numpy_image(image_black.learnable_image()[:3])\n",
    "\n",
    "params=list(image_black.parameters())\n",
    "icecream.ic(len(params))\n",
    "optim=torch.optim.Adam(params,lr=1e-3/5)#For fourier. 1e-2 is too high.\n",
    "# optim=torch.optim.Adam(params,lr=1e-2)#Normally this is too high, as the colors start to get too strong...but in this case, we want a binary mask anyway lol - might as well do it the fast way!\n",
    "# optim=torch.optim.Adam(params,lr=1e-2/5)#Normally this is too high, as the colors start to get too strong...but in this case, we want a binary mask anyway lol - might as well do it the fast way!\n",
    "# optim=torch.optim.Adam(params,lr=1e-1)#For raster. \n",
    "# optim=torch.optim.SGD(params,lr=1e-1)#For raster\n",
    "# optim=torch.optim.SGD(params,lr=1e-5)#For raster\n",
    "\n",
    "ds_black=[]\n",
    "ds_white=[]\n",
    "ds_red  =[]\n",
    "ds_green=[]\n",
    "ds_blue =[]\n",
    "alphas=[]\n",
    "fulls=[]\n",
    "alpha_sums=[]\n",
    "iter_num=0\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb1d082-11f1-4624-8105-46dfdd09c1ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SKIP=10\n",
    "\n",
    "ALPHA_HATE=1e-1\n",
    "ALPHA_HATE=0\n",
    "\n",
    "et=rp.eta(10000)\n",
    "try:\n",
    "    for _ in range(10000):\n",
    "        et(_)\n",
    "        iter_num+=1\n",
    "\n",
    "        speedup=2#1 for slow and 5 for fastest. 2 works well.\n",
    "\n",
    "        includes=rp.random_batch(range(5),speedup)\n",
    "        if 0 in includes: s.train_step(text_black,image_black()[None],by_loss=False)\n",
    "        if 1 in includes: s.train_step(text_white,image_white()[None],by_loss=False)\n",
    "        if 2 in includes: s.train_step(text_red  ,image_red  ()[None],by_loss=False)\n",
    "        if 3 in includes: s.train_step(text_green,image_green()[None],by_loss=False)\n",
    "        if 4 in includes: s.train_step(text_blue ,image_blue ()[None],by_loss=False)\n",
    "\n",
    "        # (image_black.learnable_image()[3].mean()*100000).backward(retain_graph=True) #Make alpha small\n",
    "        alpha_sum=image_black.learnable_image()[3].sum()\n",
    "        alpha_sums.append(float(alpha_sum))\n",
    "        (alpha_sum*ALPHA_HATE).backward(retain_graph=True) #Make alpha small\n",
    "\n",
    "        # s.train_step(text_black,image_black.learnable_image()[3:].repeat(3,1,1)[None],by_loss=False) #Run it on the alpha channel too!!\n",
    "\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if not _%SKIP:\n",
    "                ds_black.append(rp.as_numpy_image(image_black()))\n",
    "                ds_white.append(rp.as_numpy_image(image_white()))\n",
    "                fulls.append(rp.as_numpy_image(image_full()))\n",
    "                alphas.append(image_alpha())\n",
    "                # ds_red  .append(rp.as_numpy_image(image_red  ()))\n",
    "                # ds_green.append(rp.as_numpy_image(image_green()))\n",
    "                # ds_blue .append(rp.as_numpy_image(image_blue ()))\n",
    "            if not _%50:\n",
    "                do_display(img_only=True)\n",
    "                icecream.ic(iter_num,float(alpha_sum))\n",
    "            elif not _%500:\n",
    "                ...\n",
    "                from IPython.display import clear_output\n",
    "                clear_output()\n",
    "                # import IPython\n",
    "                # IPython.\n",
    "\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "except KeyboardInterrupt:\n",
    "    rp.line_graph_via_bokeh(alpha_sums,ylabel='Total Alpha',xlabel='Iteration')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c11a83-6b17-4a24-88b2-daba9f2d74cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display(skip=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8338e5-a285-4fba-8f9f-edb40a144fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display(skip=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b822fdcc-31d3-4c1a-a2e8-5f82af140590",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display(skip=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284db3ae-c4dc-4742-bf8e-839f9e746c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cce137-c305-4c22-a7fe-2ed2ac10130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display(skip=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcbd71d-acbb-4023-9359-dd1a3af9a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display(skip=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7842ce-6849-4260-af5a-42cf6bbd4b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display(skip=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d985545d-cfe5-4ea1-89e3-e144f8304209",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display(skip=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39519af5-9b37-48e2-95e3-36b2f50051f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display(skip=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c270ac5-d226-427b-ac15-bcf6e8b38231",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display(skip=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd18083a-a661-44fd-8b11-33ff893bfd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display(skip=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f588e6-74df-4e7b-937e-2364000d2f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display(skip=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c66f28-b739-47eb-bf6f-039311f1a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display(skip=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa1a6b7-95c4-4387-a076-205d774a17ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display(skip=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc44e59-a144-4612-b3ad-94737ca0bbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display(skip=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599775ee-152d-4c6d-b3fc-8cb355e41f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display(skip=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeff4f8-7e7d-4c3a-a8ee-4eebdc6a09a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display(skip=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edead850-609a-4763-b070-eefe92d53813",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display(skip=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc268bf-af18-4741-a5c2-7274ab9d455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display(skip=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9e9df4-1d89-4079-98dc-6e4f46943d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display(skip=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3c2890-71ff-4b8b-979b-09bdb1469938",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display(skip=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c3dc36-70f3-45e6-884f-1ea4ffa10778",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display(skip=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0a3092-a31b-40d9-b72a-1b5515262c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display(skip=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079313f2-aeb8-43a3-a4d9-c0bc4ecc1a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display(skip=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb1f87e-104c-4a39-9c47-2ef895c57225",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display(skip=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a7b565-dbf3-4694-b229-433c47ae6af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display(skip=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
