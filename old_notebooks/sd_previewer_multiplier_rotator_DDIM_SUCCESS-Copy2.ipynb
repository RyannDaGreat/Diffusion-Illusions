{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa671b1-0315-4c41-b876-fb62bf9c9439",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"HELO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ec7b35-00c7-4ec8-beb3-205a09d1f5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic\n",
    "import numpy as np\n",
    "import rp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import source.stable_diffusion as sd\n",
    "from easydict import EasyDict\n",
    "from source.learnable_textures import (LearnableImageFourier,\n",
    "                                       LearnableImageFourierBilateral,\n",
    "                                       LearnableImageRaster,\n",
    "                                       LearnableImageRasterBilateral,\n",
    "                                       LearnableTexturePackFourier,\n",
    "                                       LearnableTexturePackRaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3ad4a1-e8b2-4db6-ba6e-cb4da32fb97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 's' not in dir():\n",
    "    model_name=\"CompVis/stable-diffusion-v1-4\"\n",
    "    gpu='cuda:0'\n",
    "    s=sd.StableDiffusion(gpu,model_name)\n",
    "device=s.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747f66e9-c2f3-463f-bb21-7010b80ecbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLabel:\n",
    "    def __init__(self, name:str, embedding:torch.Tensor):\n",
    "        #Later on we might have more sophisticated embeddings, such as averaging multiple prompts\n",
    "        #We also might have associated colors for visualization, or relations between labels\n",
    "        self.name=name\n",
    "        self.embedding=embedding\n",
    "        \n",
    "    def get_sample_image(self):\n",
    "        with torch.no_grad():\n",
    "            output=s.embeddings_to_imgs(self.embedding)[0]\n",
    "        assert rp.is_image(output)\n",
    "        return output\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return '%s(name=%s)'%(type(self).__name__,self.name)\n",
    "        \n",
    "class SimpleLabel(BaseLabel):\n",
    "    def __init__(self, name:str):\n",
    "        super().__init__(name, s.get_text_embeddings(name).to(device))\n",
    "\n",
    "class NegativeLabel(BaseLabel):\n",
    "    def __init__(self, name:str, negative_prompt=''):\n",
    "        \n",
    "        if '---' in name:\n",
    "            #You can use '---' in a prompt to specify the negative part\n",
    "            name,additional_negative_prompt=name.split('---',maxsplit=1)\n",
    "            negative_prompt+=' '+additional_negative_prompt\n",
    "            \n",
    "        self.negative_prompt=negative_prompt\n",
    "        old_uncond_text=s.uncond_text\n",
    "        try:\n",
    "            s.uncond_text=negative_prompt\n",
    "            embedding = s.get_text_embeddings(name).to(device)\n",
    "            super().__init__(name, embedding)\n",
    "        finally:\n",
    "            s.uncond_text=old_uncond_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec33708-ffce-4bcc-8c27-c5b59db20436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY GOOD PROMPTS HERE\n",
    "good_prompts = EasyDict(\n",
    "    kitten_in_box = 'A orange cute kitten in a cardboard box in times square',\n",
    "    botw_landscape = 'The Legend of Zelda landscape atmospheric, hyper realistic, 8k, epic composition, cinematic, octane render, artstation landscape vista photography by Carr Clifton & Galen Rowell, 16K resolution, Landscape veduta photo by Dustin Lefevre & tdraw, 8k resolution, detailed landscape painting by Ivan Shishkin, DeviantArt, Flickr, rendered in Enscape, Miyazaki, Nausicaa Ghibli, Breath of The Wild, 4k detailed post processing, artstation, rendering by octane, unreal engine â€”ar 16:9',\n",
    "    magic_emma_watson = 'ultra realistic photo portrait of Emma Watson cosmic energy, colorful, painting burst, beautiful symmetrical face, nonchalant kind look, realistic round eyes, tone mapped, intricate, elegant, highly detailed, digital painting, artstation, concept art, smooth, sharp focus, illustration, dreamy magical atmosphere, art by artgerm and greg rutkowski and alphonse mucha, 4k, 8k',\n",
    "    yorkshire_terrier_santa = 'Insanely detailed studio portrait shot photo of intricately detailed beautiful yorkshire terrier dressed as santa clause, smirking mischievously at the camera with mischievous detailed yellow green eyes , very detailed, rim light, photo, rim light, ultra-realistic, photorealistic, hyper detailed, photography, shot on Canon DSLR, f/2. 8 , photography by Felix Kunze and Annie Leibovitz and retouched by Pratik Naik',\n",
    "    norwegian_winter_girl = 'professional portrait photograph of a gorgeous Norwegian girl in winter clothing with long wavy blonde hair, freckles, gorgeous symmetrical face, cute natural makeup, wearing elegant warm winter fashion clothing, ((standing outside in snowy city street)), mid shot, central image composition, (((professionally color graded))), (((bright soft diffused light)))',\n",
    "    magic_forest_temple = '8 k concept art from a hindu temple lost in the jungle by david mattingly and samuel araya and michael whelan and dave mckean and richard corben. realistic matte painting with photorealistic hdr volumetric lighting. composition and layout inspired by gregory crewdson. ',\n",
    "    sailing_ship = 'a big sailing ship in heavy sea, hypermaximalistic, high details, cinematic, 8k resolution, beautiful detailed, insanely intricate details, artstation trending, octane render, unreal engine',\n",
    "    bioshock_lighthouse = 'giant standalone lighthouse from bioshock infinite in england 1 9 century, half - ruined, covered by mold, staying in 2 kilometers far from a coast, opposite the dark cave - crack of giant rocks. when you see this lighthouse it makes you anxious. deep ones is living under this. view from sea, and view from the coast, by greg rutkowski',\n",
    "    two_bunnys_hugging = 'photo of bunny hugging another bunny, dramatic light, pale sunrise, cinematic lighting',\n",
    "    thomas_tank_military = 'thomas the tank engine as a military tank, intricate, highly detailed, centered, digital painting, artstation, concept art, smooth, sharp focus, illustration, artgerm, tomasz alen kopera, peter mohrbacher, donato giancola, joseph christian leyendecker, wlop, boris vallejo',\n",
    "    wolf_on_rock = 'a wolf with a tail, standing heroically on a rock. adventurous, new adventure, with a tail, forest, rocks, stream, ripples, tribal armor, female, wolf wolf wolf, atmospheric lighting, stunning, brave. by makoto shinkai, stanley artgerm lau, wlop, rossdraws, james jean, andrei riabovitchev, marc simonetti, krenz cushart, sakimichan, d & d trending on artstation, digital art. ',\n",
    "    lolita_dress_girl = 'lolita dress, angelic pretty, award winning photograph trending on artstation',\n",
    "    lolita_dress_magical_elf = 'lolita dress, angelic pretty, portrait of magical lolita woman elf elven,  hyperrealism photography hdr 4k 3d, dreamy and ethereal, fantasy, intricate, elegant, many rainbow bubbles, rose tones, highly detailed, artstation, concept art, cyberpunk wearing, smooth, sharp focus, illustration, art by artgerm and greg rutkowskiand alphonse mucha',\n",
    "    pencil_giraffe_head = 'an intricate detailed hb pencil sketch of a giraffe head',\n",
    "    pencil_penguin = 'an intricate detailed hb pencil sketch of a penguin',\n",
    "    pencil_violin = 'an intricate detailed hb pencil sketch of a violin',\n",
    "    pencil_orca_whale = 'an orca whale spouting water intricate detailed hb pencil sketch of an black white spotted orca whale',\n",
    "    pencil_cow = 'an intricate detailed hb pencil sketch of a black white spotted cow',\n",
    "    pencil_walrus = 'an intricate detailed hb pencil sketch of a walrus',\n",
    "    pencil_cat_head = 'an sketch of a cat head',\n",
    "    ape_with_gun = 'detailed science - fiction character portrait of a silverback gorilla shooting a alien gun in space, intricate, wild, highly detailed, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha',\n",
    "    human_skeleton = 'weta disney pixar movie still macro close photo of a skeleton with triopan cones for hands. his hands are triopan cones. : : by weta, greg rutkowski, wlop, ilya kuvshinov, rossdraws, artgerm, octane render, iridescent, bright morning, anime, liosh, mucha : :',\n",
    "    gold_coins = 'an old wooden table covered in gold coins and treasure, detailed oil painting, trending on Artstation',\n",
    "    golf_ball_in_forest = 'photo of a golf ball in a magical forest. dof. Bokeh. By greg rutkowski. Nikon D850. Award winning',\n",
    "    bear_in_forest = 'photo of a brown bear attacking the camera. Nikon D850. Award winning. Scary teeth claws full body shot cinematic movie',\n",
    "    elephant_in_circus = 'photo of a elephant in a magical circus. dof. Bokeh. By greg rutkowski. Nikon D850. Award winning.',\n",
    "    mickey_mouse = 'mickey mouse oil on canvas, artstation trending',\n",
    "    mushroom = 'a mushroom in a magical forest. dof. Bokeh. By greg rutkowski. Nikon D850. Award winning',\n",
    "    mario = 'mario 3d nintendo video game',\n",
    "    burger = 'big juicy hamburger with cheese and tomato and lettuice. Sesame seed bun. Advertisement beautiful dlsr hdr bokeh. ',\n",
    "    darth_vader = 'photo of a ultra realistic darth vader dramatic light, muscle, cinematic lighting, battered, low angle, static, 4k, hyper realistic, focused, extreme details, bokeh blackground, cinematic, masterpiece, intricate artwork, details,',\n",
    "    gandalf = 'Gandalf the Grey Wizard in Moonlight by Alan Lee, Glowing staff, full body concept art, intricate clothing, micro detail, octane render, 4K, art station',\n",
    "    fantasy_city = 'an ultra detailed matte painting of the quaint capital city of galic, grid shaped city cobblestone streets, fantasy city, light snowfall, wind, inspiring renaissance architecture, ultrawide lense, aerial photography, unreal engine, exquisite detail, 8 k, art by greg rutkowski and alphonse mucha',\n",
    "    green_elf_girl = 'a highly detailed portrait painting of a beautiful healer elf female male, long brown hair with braids and green highlights, long elf ears, asian decent, facial tribal markings, by greg rutkowski and alphonse mucha, sharp focus, matte, concept art, artstation, digital painting',\n",
    "    pikachu = 'Manga cover illustration of an extremely cute and adorable beautiful pikachu running through a flower field, summer vibrance, 3d render diorama by hayao miyazaki, official studio ghibli still, color graflex macro photograph, pixiv, daz studio 3d',\n",
    "    spring = 'Photographic spring season, artstation trending Nikon D850. Award winning. A bee on a flower.',\n",
    "    fall = 'Photographic fall season, artstation trending Nikon D850. Award winning. Giant Orange maple leaf. Leaf pile. Pumpkins. Halloween.',\n",
    "    winter = 'Photographic winter season, artstation trending Nikon D850. Award winning. Snow and mountains. Snowman and log cabin. Snowflakes. Ice. Icicles. Cold.',\n",
    "    summer = 'Photographic summer season, artstation trending Nikon D850. Award winning. Sun. Hot. Beach. Desert sand. Picnic. Umbrella from sun. ',\n",
    "    miku = 'Hatsune miku, gorgeous, amazing, elegant, intricate, highly detailed, digital painting, artstation, concept art, sharp focus, illustration, art by ross tran',\n",
    "    pyramids = 'An anthropomorphic beautiful great futuristic pyramid civilisation in a desert, gold, sphinx, dungeon temple, fine art, award winning, intricate, elegant, sharp focus, octane render, hyperrealistic, cinematic lighting, highly detailed, digital painting, 8 k concept art, art by jamie hewlett and z. w. gu, masterpiece, trending on artstation, 8 k',\n",
    "    dinosaur = 'A t - rex in star wars, movie still frame, hd, remastered, cinematic lighting',\n",
    "    lipstick = 'lipstick. product photo. glamour photography. 2 0 1 8. ',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c793c1ee-fa66-44e4-abab-d4dd1ca2dc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.display_image(NegativeLabel(\n",
    "    good_prompts.green_elf_girl\n",
    ").get_sample_image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15243c8f-8339-4175-bed0-e0314112e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY GOOD PROMPTS HERE\n",
    "prompt_w = good_prompts.thomas_tank_military\n",
    "prompt_w = good_prompts.human_skeleton\n",
    "\n",
    "prompt_y = good_prompts.kitten_in_box\n",
    "prompt_y = good_prompts.darth_vader\n",
    "prompt_y = good_prompts.mickey_mouse\n",
    "\n",
    "prompt_x = good_prompts.pikachu\n",
    "\n",
    "prompt_z = good_prompts.mario\n",
    "prompt_z = good_prompts.norwegian_winter_girl\n",
    "\n",
    "\n",
    "# prompt_a = good_prompts.gandalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e71d33-8f6e-4ae0-aa9b-80e723034211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY GOOD PROMPTS HERE\n",
    "prompt_w = good_prompts.summer\n",
    "prompt_y = good_prompts.fall\n",
    "prompt_x = good_prompts.winter\n",
    "prompt_z = good_prompts.spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a73589d-cbe1-402a-b617-a01df85e93e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt_w, prompt_x, prompt_y, prompt_z = rp.gather(good_prompts, 'miku pyramids dinosaur lipstick'.split())\n",
    "prompt_w, prompt_x, prompt_y, prompt_z = rp.gather(good_prompts, 'pencil_violin pencil_cow pencil_cat_head pencil_penguin'.split())\n",
    "prompt_w, prompt_x, prompt_y, prompt_z = rp.gather(good_prompts, 'miku green_elf_girl norwegian_winter_girl magic_emma_watson'.split())\n",
    "prompt_w, prompt_x, prompt_y, prompt_z = rp.gather(good_prompts, 'elephant_in_circus summer winter two_bunnys_hugging'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5707710-66d9-453e-8e56-b031c78d7924",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_prompt = ''\n",
    "label_w = NegativeLabel(prompt_w,negative_prompt)\n",
    "label_x = NegativeLabel(prompt_x,negative_prompt)\n",
    "label_y = NegativeLabel(prompt_y,negative_prompt)\n",
    "label_z = NegativeLabel(prompt_z,negative_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1c3a66-f2d3-4917-80f4-61c4f7fcfff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Factors\")\n",
    "rp.display_image(label_w.get_sample_image())\n",
    "rp.display_image(label_x.get_sample_image())\n",
    "rp.display_image(label_y.get_sample_image())\n",
    "rp.display_image(label_z.get_sample_image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24d7390-a556-4096-8e7d-7f25a9ed6c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters (this section takes vram)\n",
    "\n",
    "#Select Learnable Image Type:\n",
    "learnable_image_maker = lambda:LearnableImageFourier().to(s.device)\n",
    "# learnable_image_maker = lambda:LearnableImageFourier(height=512,width=512,num_features=512,hidden_dim=512,scale=20).to(s.device)\n",
    "\n",
    "factor_base=learnable_image_maker()\n",
    "factor_rotator=learnable_image_maker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee8dd01-e350-42d3-a939-cdfa7b61a960",
   "metadata": {},
   "outputs": [],
   "source": [
    "brightness=3\n",
    "\n",
    "def simulate_overlay(bottom, top):\n",
    "    exp=rp.random_float(.5,1)\n",
    "    brightness=rp.random_float(1,5)\n",
    "    black=rp.random_float(0,.5)\n",
    "    bottom=rp.blend(bottom,black,rp.random_float())\n",
    "    top=rp.blend(top,black,rp.random_float())\n",
    "    return (bottom**exp * top**exp * brightness).clamp(0,99).tanh()\n",
    "\n",
    "learnable_image_w=lambda: simulate_overlay(factor_base(), factor_rotator().rot90(k=0,dims=[1,2]))\n",
    "learnable_image_x=lambda: simulate_overlay(factor_base(), factor_rotator().rot90(k=1,dims=[1,2]))\n",
    "learnable_image_y=lambda: simulate_overlay(factor_base(), factor_rotator().rot90(k=2,dims=[1,2]))\n",
    "learnable_image_z=lambda: simulate_overlay(factor_base(), factor_rotator().rot90(k=3,dims=[1,2]))\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "params=chain(\n",
    "    factor_base.parameters(),\n",
    "    factor_rotator.parameters(),\n",
    ")\n",
    "optim=torch.optim.SGD(params,lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4974c4-a6ab-4301-9c4d-722ce5976c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "brightness=3\n",
    "\n",
    "CLEAN_MODE=False\n",
    "def simulate_overlay(bottom, top):\n",
    "    if CLEAN_MODE:\n",
    "        exp=1\n",
    "        brightness=3\n",
    "        black=0\n",
    "    else:\n",
    "        exp=rp.random_float(.5,1)\n",
    "        brightness=rp.random_float(1,5)\n",
    "        black=rp.random_float(0,.5)\n",
    "        bottom=rp.blend(bottom,black,rp.random_float())\n",
    "        top=rp.blend(top,black,rp.random_float())\n",
    "    return (bottom**exp * top**exp * brightness).clamp(0,99).tanh()\n",
    "\n",
    "learnable_image_w=lambda: simulate_overlay(factor_base(), factor_rotator().rot90(k=0,dims=[1,2]))\n",
    "learnable_image_x=lambda: simulate_overlay(factor_base(), factor_rotator().rot90(k=1,dims=[1,2]))\n",
    "learnable_image_y=lambda: simulate_overlay(factor_base(), factor_rotator().rot90(k=2,dims=[1,2]))\n",
    "learnable_image_z=lambda: simulate_overlay(factor_base(), factor_rotator().rot90(k=3,dims=[1,2]))\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "params=chain(\n",
    "    factor_base.parameters(),\n",
    "    factor_rotator.parameters(),\n",
    ")\n",
    "optim=torch.optim.SGD(params,lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dc589e-debf-46e3-b3c9-2257ed623717",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_MODE=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e698be8-183d-4849-be08-fe950e25ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num=4\n",
    "nums=[0,1,2,3]\n",
    "# nums=[0  ,2,3]\n",
    "# nums=[    2  ]\n",
    "# nums=[0,1,2]\n",
    "# nums=[1]\n",
    "# nums=[0,1]\n",
    "# nums=[0,2]\n",
    "\n",
    "\n",
    "labels=[label_w,label_x,label_y,label_z]\n",
    "learnable_images=[learnable_image_w,learnable_image_x,learnable_image_y,learnable_image_z]\n",
    "weights=[1,1,1,1]\n",
    "\n",
    "labels=[labels[i] for i in nums]\n",
    "learnable_images=[learnable_images[i] for i in nums]\n",
    "weights=[weights[i] for i in nums]\n",
    "\n",
    "weights=rp.as_numpy_array(weights)\n",
    "weights=weights/weights.sum()\n",
    "weights=weights*len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d428ba1-c415-47dd-9a92-777ae7e5b400",
   "metadata": {},
   "outputs": [],
   "source": [
    "pims=[]\n",
    "ims=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1989b01-87c4-4b4f-a330-21c7f0422f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ITER=100000\n",
    "s.max_step=MAX_STEP=990\n",
    "# s.min_step=MIN_STEP=450\n",
    "s.min_step=MIN_STEP=10\n",
    "\n",
    "et=rp.eta(NUM_ITER)\n",
    "\n",
    "# folder='sd_previewer_results2/'+prompt[:100]+rp.random_namespace_hash()\n",
    "# rp.make_folder(folder)\n",
    "\n",
    "for iter_num in range(NUM_ITER):\n",
    "    \n",
    "    step = rp.blend(MAX_STEP,MIN_STEP,iter_num/NUM_ITER)\n",
    "    # s.min_step = s.max_step = int(step)\n",
    "    \n",
    "    et(iter_num)\n",
    "\n",
    "    # image=learnable_image()\n",
    "    # variants=list(get_variants(image,label))\n",
    "    # num_variants=len(variants)\n",
    "    \n",
    "    preds=[]\n",
    "    for label,learnable_image,weight in rp.random_batch(list(zip(labels,learnable_images,weights)),1):\n",
    "        pred=s.train_step(\n",
    "            label.embedding,\n",
    "            learnable_image()[None],\n",
    "\n",
    "            #PRESETS (uncomment one):\n",
    "            noise_coef=.1*weight,guidance_scale=60,#10\n",
    "            # noise_coef=0,image_coef=-.01,guidance_scale=50,\n",
    "            # noise_coef=0,image_coef=-.005,guidance_scale=50,\n",
    "            # noise_coef=.1,image_coef=-.010,guidance_scale=50,\n",
    "            # noise_coef=.1,image_coef=-.005,guidance_scale=50,\n",
    "            # noise_coef=.1*weight, image_coef=-.005*weight, guidance_scale=50,\n",
    "        )\n",
    "        preds+=list(pred)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if not iter_num%(200*100):\n",
    "            from IPython.display import clear_output\n",
    "            clear_output()\n",
    "        # if not iter_num%20:\n",
    "        if not iter_num%200:\n",
    "            im=rp.tiled_images(\n",
    "                [\n",
    "                    *[rp.as_numpy_image(image()) for image in learnable_images],\n",
    "                    rp.as_numpy_image(factor_base()),\n",
    "                    rp.as_numpy_image(factor_rotator()),\n",
    "                ],\n",
    "                length=len(learnable_images),\n",
    "                border_thickness=0,\n",
    "            )\n",
    "            ims.append(im)\n",
    "            # rp.save_image(im,folder+'/%06i.png'%iter_num)\n",
    "            rp.display_image(im)\n",
    "            \n",
    "        if False and not iter_num%200:\n",
    "            pim=rp.tiled_images([\n",
    "                *rp.as_numpy_images(s.decode_latents(torch.stack(preds))),\n",
    "            ])\n",
    "            pims.append(pim)\n",
    "            rp.display_image(pim)\n",
    "            \n",
    "    optim.step()\n",
    "    optim.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b64cea-1a6e-4e2f-a5f9-32c5c38224d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_run(name):\n",
    "    folder=\"untracked/rotator_multiplier_runs/%s\"%name\n",
    "    if rp.path_exists(folder):\n",
    "        # folder+='_'+rp.random_namespace_hash(4)\n",
    "        import time\n",
    "        folder+='_%i'%time.time()\n",
    "    rp.make_directory(folder)\n",
    "    pims_names=['pims_%04i.png'%i for i in range(len(pims))]\n",
    "    ims_names=['ims_%04i.png'%i for i in range(len(ims))]\n",
    "    with rp.SetCurrentDirectoryTemporarily(folder):\n",
    "        rp.save_images(pims,pims_names,show_progress=True)\n",
    "        rp.save_images(ims,ims_names,show_progress=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "save_run('elephantsunsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be265947-d7cd-4b22-8df8-52c234c36043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "@rp.monkey_patch(sd.StableDiffusion)\n",
    "def redenoise_latent(self,                   text_embeddings:torch.Tensor,\n",
    "                   latent:torch.Tensor,\n",
    "                   guidance_scale:float=16,\n",
    "                   t:int=None,):\n",
    "        \n",
    "        if t is None:\n",
    "            t = torch.randint(self.min_step, self.max_step + 1, [1], dtype=torch.long, device=self.device)\n",
    "\n",
    "        assert 0<=t<self.num_train_timesteps, 'invalid timestep t=%i'%t\n",
    "\n",
    "        latents=latent[None]\n",
    "\n",
    "        \n",
    "        # predict the noise residual with unet, NO grad!\n",
    "        with torch.no_grad():\n",
    "            # add noise\n",
    "            noise = torch.randn_like(latents)\n",
    "            #This is the only place we use the scheduler...the add_noise function. What's more...it's totally generic! The scheduler doesn't impact the implementation of train_step...\n",
    "            latents_noisy = self.add_noise(latents, noise, t) #The add_noise function is identical for PNDM, DDIM, and DDPM schedulers in the diffusers library\n",
    "            #TODO: Expand this add_noise function, and put it in this class. That way we don't need the scheduler...and we can also add an inverse function, which is what I need for previews...that subtracts noise...\n",
    "            #Also, create a dream-loss-based image gen example notebook...\n",
    "\n",
    "            # pred noise\n",
    "            latent_model_input = torch.cat([latents_noisy] * 2)\n",
    "            noise_pred = self.predict_noise(latent_model_input, text_embeddings, t)\n",
    "\n",
    "                        \n",
    "            noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
    "            noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
    "            \n",
    "            latent_pred = self.remove_noise(latents_noisy, noise_pred, t)\n",
    "            # rp.ic(latent_pred.shape)\n",
    "            output = latent_pred[0]\n",
    "            \n",
    "            # latent_pred = self.decode_latents(latent_pred)[0]\n",
    "\n",
    "        return latent_pred[0]\n",
    "\n",
    "\n",
    "    \n",
    "def denoise_l(latent,label,T):\n",
    "    return s.redenoise_latent(latent=latent,\n",
    "                              text_embeddings=label.embedding,\n",
    "                              t=torch.tensor(T, dtype=torch.int)\n",
    "                             )\n",
    "    \n",
    "def get_ii_seqo(w=learnable_image_w, lw=label_w):\n",
    "    seqo=[]\n",
    "    with torch.no_grad():\n",
    "        # w,lw=learnable_image_x,label_x\n",
    "        # w,lw=learnable_image_y,label_y\n",
    "        # w,lw=learnable_image_z,label_z\n",
    "\n",
    "        lw=NegativeLabel(lw.name,'blurry blurry blurry unfocused low quality out of focus')\n",
    "\n",
    "        w=w()\n",
    "        i=w\n",
    "        i = F.interpolate(i[None], (512, 512), mode='bilinear', align_corners=False)[0]\n",
    "        l=s.encode_img(i)\n",
    "        ol=l\n",
    "\n",
    "        rp.display_image(rp.as_numpy_image(i))\n",
    "\n",
    "        # for T in [10]*100:\n",
    "        # for T in [100,100,100,100,100]*10:\n",
    "        # for T in [100,100,100,100,100]:\n",
    "        rp.tic()\n",
    "        # for T in list(range(999, 0, -10)):\n",
    "        # for T in list(range(500, 0, -10)):\n",
    "        # for T in list(range(999, 0, -50)):\n",
    "        # for T in list(range(100, 0, -1)):\n",
    "        for T in list(range(100, 75, -1)):\n",
    "\n",
    "            # torch.manual_seed(298)\n",
    "\n",
    "            dl=denoise_l(l, lw, T)\n",
    "            # l=rp.blend(l,dl,1)#Stick to the previous, EMA, make it smooth! Less variance\n",
    "            l=rp.blend(l,dl,.2)#Stick to the previous, EMA, make it smooth! Less variance\n",
    "            # l=rp.blend(l,dl,.01)#Stick to the previous, EMA, make it smooth! Less variance\n",
    "\n",
    "            # l=rp.blend(l,ol,.05)#Stick to the original\n",
    "            # l=dl\n",
    "\n",
    "            from IPython.display import clear_output\n",
    "            # clear_output()\n",
    "\n",
    "            ii=rp.as_numpy_image(s.decode_latent(l))\n",
    "            print(T)\n",
    "            seqo.append(ii)\n",
    "            if rp.toc()>10:\n",
    "                rp.display_image(ii)\n",
    "                rp.tic()\n",
    "        rp.display_image(ii)\n",
    "        return ii,seqo\n",
    "# rp.display_image_slideshow(seqo)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eef71e5-1632-4baf-9da8-990726c3eec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "WI,seqo=get_ii_seqo(learnable_image_w,label_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b28a68-a7fe-4967-9558-b3b36835ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "XI,seqo=get_ii_seqo(learnable_image_x,label_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df071b6c-68da-4c7b-a486-60855e3bc38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "YI,seqo=get_ii_seqo(learnable_image_y,label_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e898cf57-7d62-4d29-aa54-bcedabb701f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZI,seqo=get_ii_seqo(learnable_image_z,label_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf7364d-225e-44c7-8598-113acfaf6048",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rp.display_image(rp.tiled_images([WI,XI,YI,ZI]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2271faeb-7902-4a68-a047-8cf00f253090",
   "metadata": {},
   "outputs": [],
   "source": [
    "down_images=rp.as_torch_images(rp.as_numpy_array([rp.cv_resize_image(rp.as_numpy_image(x),(256,256)) for x in [WI,XI,YI,ZI]])).to(s.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148f57ad-f6c2-4a4b-81bf-b07f832b0566",
   "metadata": {},
   "outputs": [],
   "source": [
    "shlump=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c63f5e7-f9c3-4ad9-8059-e34fa80787b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10000):\n",
    "    loss_w=((learnable_image_w()-down_images[0])**2).mean()\n",
    "    loss_x=((learnable_image_x()-down_images[1])**2).mean()\n",
    "    loss_y=((learnable_image_y()-down_images[2])**2).mean()\n",
    "    loss_z=((learnable_image_z()-down_images[3])**2).mean()\n",
    "    \n",
    "    total_loss=loss_w+loss_x+loss_y+loss_z\n",
    "    total_loss=total_loss*10000\n",
    "    \n",
    "    total_loss.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "    print(total_loss)\n",
    "    \n",
    "    if not _%100:\n",
    "        shlumper=rp.tiled_images(\n",
    "            [\n",
    "                rp.as_numpy_image(learnable_image_w()),\n",
    "                rp.as_numpy_image(learnable_image_x()),\n",
    "                rp.as_numpy_image(learnable_image_y()),\n",
    "                rp.as_numpy_image(learnable_image_z()),\n",
    "                rp.as_numpy_image(factor_base()),\n",
    "                rp.as_numpy_image(factor_rotator()),\n",
    "                \n",
    "            ],\n",
    "            border_thickness=0,\n",
    "            length=4\n",
    "        )\n",
    "        rp.display_image(shlumper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eea7c3-833c-4e04-939e-2d4ff003c8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "im=rp.tiled_images([\n",
    "    *rp.as_numpy_array(rp.as_numpy_images(preds),)\n",
    "])\n",
    "# rp.save_image(im,folder+'/%06i.png'%iter_num)\n",
    "rp.display_image(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcf419c-1ded-4abb-aaaf-911f70fab742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746587b3-b648-4052-90e5-90d4291bd22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack(preds).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef719b0-20fb-42d1-b512-e15093f7efec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a0b129-826b-45e9-9053-76eb7bb7cef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.display_image(ims[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb94e326-e0c3-46be-b3c0-81b101791b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.display_image_slideshow(ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b247145-b314-4a2a-8a6e-2e1fc44f3ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out=rp.save_video_mp4(ims,'videos/%s.mp4'%rp.random_namespace_hash())\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a9cda2-70f3-4d12-a555-4c2a56f6c769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38c5f2d-3d42-49ed-a33f-e3b7cc2bf42d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928f8243-15be-4ac8-b1b4-e26b7c67de7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d635f86f-3b1d-42f2-be36-af923e186675",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc97baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_run(name):\n",
    "    folder=\"untracked/rotator_multiplier_runs/%s\"%name\n",
    "    if rp.path_exists(folder):\n",
    "        # folder+='_'+rp.random_namespace_hash(4)\n",
    "        import time\n",
    "        folder+='_%i'%time.time()\n",
    "    rp.make_directory(folder)\n",
    "    pims_names=['pims_%04i.png'%i for i in range(len(pims))]\n",
    "    ims_names=['ims_%04i.png'%i for i in range(len(ims))]\n",
    "    with rp.SetCurrentDirectoryTemporarily(folder):\n",
    "        rp.save_images(pims,pims_names,show_progress=True)\n",
    "        rp.save_images(ims,ims_names,show_progress=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "save_run('elephantsunsets')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
