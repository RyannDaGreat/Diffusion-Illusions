{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f649f65c-cda2-4388-9489-493590f06249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "import json\n",
    "import cv2 as cv\n",
    "from tqdm import tqdm\n",
    "\n",
    "def IOU(a, b):\n",
    "    assert a.shape == b.shape and len(a.shape) == 2\n",
    "    return np.count_nonzero(np.logical_and(a, b)) / np.count_nonzero(np.logical_or(a, b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1994daf8-dc46-408d-ad48-f07ac0e4415e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# VOC labels\n",
    "label_colors= np.asarray(\n",
    "        [\n",
    "            [0, 0, 0],\n",
    "            [128, 0, 0],\n",
    "            [0, 128, 0],\n",
    "            [128, 128, 0],\n",
    "            [0, 0, 128],\n",
    "            [128, 0, 128],\n",
    "            [0, 128, 128],\n",
    "            [128, 128, 128],\n",
    "            [64, 0, 0],\n",
    "            [192, 0, 0],\n",
    "            [64, 128, 0],\n",
    "            [192, 128, 0],\n",
    "            [64, 0, 128],\n",
    "            [192, 0, 128],\n",
    "            [64, 128, 128],\n",
    "            [192, 128, 128],\n",
    "            [0, 64, 0],\n",
    "            [128, 64, 0],\n",
    "            [0, 192, 0],\n",
    "            [128, 192, 0],\n",
    "            [0, 64, 128],\n",
    "        ]\n",
    "    ).astype(np.uint8)\n",
    "\n",
    "label_texts = [\n",
    "    'background',\n",
    "    'aeroplane', \n",
    "    'bicycle', \n",
    "    'bird',\n",
    "    'boat',\n",
    "    'bottle',\n",
    "    'bus',\n",
    "    'car',\n",
    "    'cat',\n",
    "    'chair',\n",
    "    'cow',\n",
    "    'diningtable',\n",
    "    'dog',\n",
    "    'horse',\n",
    "    'motorbike',\n",
    "    'person',\n",
    "    'potted plant',\n",
    "    'sheep',\n",
    "    'sofa',\n",
    "    'train',\n",
    "    'tv/monitor'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40500d5a-969e-4e60-9382-20c22d5e368f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    pred = '/nfs/ws1/ryan/CleanCode/Projects/Peekaboo/Experiments/Dreams/untracked/for_xiang/ref_voc'\n",
    "    prefix = '/nfs/ws1/datasets/RefVOC/'\n",
    "    gt = '/raid/datasets/pascal_voc/VOC2012/SegmentationClass'\n",
    "\n",
    "    from IPython.display import display\n",
    "    from PIL import Image\n",
    "\n",
    "    def zip_to_single_channel(l):\n",
    "        return (l[...,0] // 4)  + (l[...,1] // 16) + l[...,2] // 64\n",
    "\n",
    "    zipped_labels = zip_to_single_channel(label_colors).tolist()\n",
    "    print(zipped_labels)\n",
    "\n",
    "    def eval_peekaboo_voc(prefix, pred, gt):\n",
    "        unfinished = []\n",
    "        with open(os.path.join(prefix, 'cropped.txt'), 'r') as f:\n",
    "            names = f.readlines()\n",
    "\n",
    "        # random.shuffle(names)\n",
    "\n",
    "        res = []\n",
    "\n",
    "        folders = glob(f'{pred}/*')\n",
    "        methods = [folder.split('/')[-1] for folder in folders]\n",
    "\n",
    "        for name in tqdm(names):\n",
    "            words = name.split()\n",
    "            image_name = words[0]\n",
    "            cls_name = ' '.join(words[1:])\n",
    "\n",
    "            with open(f'{prefix}/cropped-{image_name}.jpg.txt', 'r') as f:\n",
    "                x1, x2, y1, y2 = f.readline().split()\n",
    "                x1 = int(x1)\n",
    "                x2 = int(x2)\n",
    "                y1 = int(y1)\n",
    "                y2 = int(y2)\n",
    "\n",
    "\n",
    "\n",
    "                gt_img = cv.imread(os.path.join(gt, f'{image_name}.png'))[y1:y2, x1:x2, ::-1]\n",
    "                gt_img = zip_to_single_channel(gt_img)\n",
    "                h, w = gt_img.shape\n",
    "                cls_idx = label_texts.index(cls_name)\n",
    "                cls_color = zipped_labels[cls_idx]\n",
    "\n",
    "                mapb = gt_img == cls_color\n",
    "\n",
    "                for method, folder in zip(methods, folders):\n",
    "                    if method == 'preview_images':\n",
    "                        continue\n",
    "                    image_target = os.path.join(folder, f'alpha', f'cropped-{image_name}.jpg')\n",
    "                    if not os.path.exists(image_target):\n",
    "                        unfinished.append(image_target)\n",
    "                        continue\n",
    "                    pred_img = cv.resize(cv.imread(image_target, 0), (w, h), cv.INTER_NEAREST)\n",
    "\n",
    "                    for t in range(10):\n",
    "                        thre = t * 255 / 10\n",
    "                        mapa = pred_img > thre\n",
    "\n",
    "                        # print(mapa.shape, mapb.shape)\n",
    "                        iou = IOU(mapa, mapb)\n",
    "                        \"\"\"\n",
    "                        # debug\n",
    "                        print(image_name, cls_name, iou)\n",
    "                        display(Image.fromarray(mapa))\n",
    "                        display(Image.fromarray(mapb))\n",
    "                        break\n",
    "                        \"\"\"\n",
    "                        res.append((iou, cls_name, f'Peekaboo-{method}', thre))\n",
    "        print(\"Unfinished images:\")\n",
    "        print(unfinished)\n",
    "        return pd.DataFrame(data=res, columns=['IoU', 'class', 'method', 'threshold']), unfinished\n",
    "    gp1, unfinished1 = eval_peekaboo_voc(prefix, pred, gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854485f3-ae6c-4722-b961-2a4c3629db99",
   "metadata": {
    "tags": []
   },
   "source": [
    "gp1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09914268-4de3-4f02-b0a5-7b18df9ecdec",
   "metadata": {
    "tags": []
   },
   "source": [
    "gp1.groupby(['method', 'class', 'threshold']).mean().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c7f26b-780c-479f-adf3-a22a83cfe19e",
   "metadata": {
    "tags": []
   },
   "source": [
    "gp1.groupby(['method', 'threshold']).mean().round(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3327b6f2-0fa8-47b3-86ca-f80d4e25c158",
   "metadata": {
    "tags": []
   },
   "source": [
    "gp1.to_pickle(\"./RefVOC-Peekaboo.pkl\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4e569b-049e-4b89-976e-8e65755c408d",
   "metadata": {
    "tags": []
   },
   "source": [
    "prefix = '/nfs/ws1/datasets/RefVOC-MO/'\n",
    "pred = '/nfs/ws1/ryan/CleanCode/Projects/Peekaboo/Experiments/Dreams/untracked/for_xiang/ref_voc_mo'\n",
    "gt = '/raid/datasets/pascal_voc/VOC2012/SegmentationClass'\n",
    "\n",
    "gp2, unfinished2 = eval_peekaboo_voc(prefix, pred, gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86536a6b-ec77-4855-b2ef-ea10ed209417",
   "metadata": {
    "tags": []
   },
   "source": [
    "gp2.groupby(['method', 'class', 'threshold']).mean().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72db047-6f27-4d1b-831c-712fd45432d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "gp2.groupby(['method', 'threshold']).mean().round(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d75a8d-4786-4077-af89-9d77d6ac3a11",
   "metadata": {
    "tags": []
   },
   "source": [
    "gp2.to_pickle(\"./RefVOC-MO-Peekaboo.pkl\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7769c482-19a4-4d73-8383-646e86420ca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import rp\n",
    "@rp.memoized\n",
    "def cv_imread(*args,**kwargs):\n",
    "    return cv.imread(*args,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa29174-7fd5-4b51-8fe9-7bd58e425d20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shows=5\n",
    "def eval_peekaboo_coco(prefix, pred, gt):\n",
    "    with open(os.path.join(prefix, 'cropped.txt'), 'r') as f:\n",
    "        names = f.readlines()\n",
    "    res = []\n",
    "    unfinished = []\n",
    "    # random.shuffle(names)\n",
    "    folders = glob(f'{pred}/*')\n",
    "    methods = [folder.split('/')[-1] for folder in folders]\n",
    "    for i, name in enumerate(tqdm(names)):\n",
    "        i = int(i)\n",
    "        words = name.split()\n",
    "        image_name = words[0]\n",
    "        png_name = image_name.replace('jpg', 'png')\n",
    "        cls_name = ' '.join(words[1:])\n",
    "        \n",
    "        bbox = f'{prefix}/{image_name}.txt'\n",
    "        if os.path.exists(bbox):\n",
    "            with open(bbox, 'r') as f:\n",
    "                x1, x2, y1, y2 = f.readline().split()\n",
    "                x1 = int(x1)\n",
    "                x2 = int(x2)\n",
    "                y1 = int(y1)\n",
    "                y2 = int(y2)\n",
    "            # print(f'{i}-{png_name}')\n",
    "            gt_img = cv_imread(os.path.join(gt, png_name), 0)[y1:y2, x1:x2]\n",
    "        else:\n",
    "            gt_img = cv_imread(os.path.join(gt, png_name), 0)\n",
    "            \n",
    "        h, w = gt_img.shape\n",
    "        mapb = gt_img > 0\n",
    "        for method, folder in zip(methods, folders):\n",
    "                if method == 'preview_images':\n",
    "                    continue\n",
    "                image_target = os.path.join(folder, f'alpha', f'{i}-{image_name}')\n",
    "                if not os.path.exists(image_target):\n",
    "                    unfinished.append(image_target)\n",
    "                    continue\n",
    "                pred_img = cv.resize(cv_imread(image_target, 0), (w, h), cv.INTER_NEAREST)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                import rp\n",
    "                \n",
    "                # #.4232\n",
    "                # alpha=pred_img\n",
    "                # std=alpha.std()\n",
    "                # alpha=alpha-alpha.mean()*.55\n",
    "                # alpha=alpha/std/2\n",
    "                # pred_img=alpha\n",
    "                # R=45\n",
    "                # pred_img=rp.cv_dilate(pred_img,R,circular=True)\n",
    "                # pred_img=rp.cv_erode(pred_img,R-5,circular=True)\n",
    "                # pred_img=rp.as_byte_image(pred_img)\n",
    "                \n",
    "                                \n",
    "                # # #.4270\n",
    "                # alpha=pred_img\n",
    "                # std=alpha.std()\n",
    "                # alpha=alpha-alpha.mean()*.55\n",
    "                # alpha=alpha/std/2\n",
    "                # pred_img=alpha\n",
    "                # pred_img=rp.cv_gauss_blur(pred_img,4)\n",
    "                # R=45\n",
    "                # pred_img=rp.cv_dilate(pred_img,R,circular=True)\n",
    "                # pred_img=rp.cv_erode(pred_img,R-6,circular=True)\n",
    "                # R=10\n",
    "                # pred_img=rp.cv_erode(pred_img,R,circular=True)\n",
    "                # pred_img=rp.cv_dilate(pred_img,R,circular=True)\n",
    "                # pred_img=rp.as_byte_image(pred_img)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                                \n",
    "                # # #.4280\n",
    "                # alpha=pred_img\n",
    "                # std=alpha.std()\n",
    "                # alpha=alpha-alpha.mean()*.55\n",
    "                # alpha=alpha/std/2\n",
    "                # pred_img=alpha\n",
    "                # pred_img=rp.cv_gauss_blur(pred_img,11)\n",
    "                # R=45\n",
    "                # pred_img=rp.cv_dilate(pred_img,R,circular=True)\n",
    "                # pred_img=rp.cv_erode(pred_img,R-6,circular=True)\n",
    "                # R=10\n",
    "                # pred_img=rp.cv_erode(pred_img,R,circular=True)\n",
    "                # pred_img=rp.cv_dilate(pred_img,R,circular=True)\n",
    "                # pred_img=rp.as_byte_image(pred_img)\n",
    "                \n",
    "                                \n",
    "#                 # #.4284\n",
    "#                 alpha=pred_img\n",
    "#                 std=alpha.std()\n",
    "#                 alpha=alpha-alpha.mean()*.55\n",
    "#                 alpha=alpha/std/2\n",
    "#                 pred_img=alpha\n",
    "#                 pred_img=rp.cv_gauss_blur(pred_img,10)\n",
    "#                 R=45\n",
    "#                 pred_img=rp.cv_dilate(pred_img,R,circular=True)\n",
    "#                 pred_img=rp.cv_erode(pred_img,R-6,circular=True)\n",
    "#                 R=9\n",
    "#                 pred_img=rp.cv_erode(pred_img,R,circular=True)\n",
    "#                 pred_img=rp.cv_dilate(pred_img,R,circular=True)\n",
    "#                 pred_img=rp.as_byte_image(pred_img)\n",
    "                \n",
    "#                                 \n",
    "                # # #.4287\n",
    "                # alpha=pred_img\n",
    "                # std=alpha.std()\n",
    "                # alpha=alpha-alpha.mean()*.56\n",
    "                # alpha=alpha/std/(2+.1)\n",
    "                # pred_img=alpha\n",
    "                # pred_img=rp.cv_gauss_blur(pred_img,10)\n",
    "                # R=45\n",
    "                # pred_img=rp.cv_dilate(pred_img,R,circular=True)\n",
    "                # pred_img=rp.cv_erode(pred_img,R-6,circular=True)\n",
    "                # R=9\n",
    "                # pred_img=rp.cv_erode(pred_img,R,circular=True)\n",
    "                # pred_img=rp.cv_dilate(pred_img,R,circular=True)\n",
    "                # pred_img=rp.as_byte_image(pred_img)\n",
    "                \n",
    "                \n",
    "#                 # #.4290\n",
    "#                 alpha=pred_img\n",
    "#                 std=alpha.std()\n",
    "#                 alpha=alpha-alpha.mean()*.56\n",
    "#                 alpha=alpha/std/(2+.1)\n",
    "#                 pred_img=alpha\n",
    "#                 pred_img=rp.cv_gauss_blur(pred_img,10)\n",
    "#                 R=45\n",
    "#                 pred_img=rp.cv_dilate(pred_img,R,circular=True)\n",
    "#                 pred_img=rp.cv_erode(pred_img,R-6,circular=True)\n",
    "#                 R=9\n",
    "#                 pred_img=rp.cv_gauss_blur(pred_img,12)\n",
    "#                 pred_img=rp.cv_erode(pred_img,R,circular=True)\n",
    "#                 pred_img=rp.cv_dilate(pred_img,R,circular=True)\n",
    "#                 pred_img=rp.as_byte_image(pred_img)\n",
    "                \n",
    "    \n",
    "                # #.4330\n",
    "                alpha=pred_img\n",
    "                std=alpha.std()\n",
    "                alpha=alpha-alpha.mean()*.56\n",
    "                alpha=alpha/std/(2+.1)\n",
    "                pred_img=alpha\n",
    "                pred_img=rp.cv_gauss_blur(pred_img,10)\n",
    "                R=45\n",
    "                pred_img=rp.cv_dilate(pred_img,R,circular=True)\n",
    "                pred_img=rp.cv_erode(pred_img,R-6,circular=True)\n",
    "                R=9\n",
    "                pred_img=rp.cv_gauss_blur(pred_img,80)\n",
    "                pred_img=rp.cv_erode(pred_img,R,circular=True)\n",
    "                pred_img=rp.cv_dilate(pred_img,R,circular=True)\n",
    "                pred_img=rp.as_byte_image(pred_img)\n",
    "                \n",
    "                \n",
    "                global shows\n",
    "                if shows:\n",
    "                    shows-=1\n",
    "                    rp.display_image(pred_img)\n",
    "                \n",
    "                N=100\n",
    "                for t in range(N):\n",
    "                    thre = t * 255 / N\n",
    "                    mapa = pred_img > thre\n",
    "\n",
    "                    # print(mapa.shape, mapb.shape)\n",
    "                    iou = IOU(mapa, mapb)\n",
    "                    \"\"\"\n",
    "                    # debug\n",
    "                    print(image_name, cls_name, iou)\n",
    "                    display(Image.fromarray(mapa))\n",
    "                    display(Image.fromarray(mapb))\n",
    "                    break\n",
    "                    \"\"\"\n",
    "                    res.append((iou, cls_name, f'Peekaboo-{method}', thre))\n",
    "    # print(\"Unfinished images:\")\n",
    "    # print(unfinished)\n",
    "    return pd.DataFrame(data=res, columns=['IoU', 'class', 'method', 'threshold']), unfinished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeac01e-ef65-4188-a6d0-6729eaa4b7a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = '/nfs/ws1/ryan/CleanCode/Projects/Peekaboo/Experiments/Dreams/untracked/for_xiang/coco_2'\n",
    "prefix = '/nfs/ws1/datasets/RefCOCO-C/'\n",
    "gt = '/nfs/ws1/datasets/RefCOCO/label/'\n",
    "\n",
    "gp3, unfinished3 = eval_peekaboo_coco(prefix, pred, gt)\n",
    "print(gp3.groupby(['method', 'threshold']).mean().round(5).IoU.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f72070-143e-4a34-8c8f-5bb6c5575d71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "# pd.set_option('display.expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d323c4ac-563f-4c19-aaab-629bfbf24808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gp3.groupby(['method', 'threshold']).mean().round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe6f09d-1d1a-4777-879d-1359ffac7541",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gp3.to_pickle(\"./RefCOCO-Peekaboo.pkl\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b596967d-3335-4c7e-a0d6-4b9144e8cc5f",
   "metadata": {},
   "source": [
    "# Fix the naming issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3ab125-632e-4c6a-8886-8524187f053e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folders = glob('/nfs/ws1/ryan/CleanCode/Projects/Peekaboo/Experiments/Dreams/untracked/for_xiang/coco_2/*')\n",
    "with open('/nfs/ws1/datasets/RefCOCO-C/cropped.txt', 'r') as f:\n",
    "    tasks = [i.split()[0] for i in f.readlines()]\n",
    "\n",
    "for folder in folders:\n",
    "    method = folder.split('/')[-1]\n",
    "    sub = 'images' if method == 'preview_images' else 'alpha'\n",
    "    \n",
    "    src = os.path.join(folder, sub)\n",
    "    \n",
    "    for img in tqdm(glob(src + '/*.jpg')):\n",
    "        n_img = img.split('/')\n",
    "        i = 0\n",
    "        filename = n_img[-1]\n",
    "        try:\n",
    "            i = tasks.index(filename)\n",
    "        except:\n",
    "            continue\n",
    "        while tasks[i+1] == filename:\n",
    "            i += 1\n",
    "        n_img[-1] = f'{i}-' + n_img[-1] \n",
    "        l_img = '/'.join(n_img)\n",
    "        if os.path.exists(l_img):\n",
    "            continue\n",
    "        os.symlink(img, l_img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
