{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8faf35fa-50fe-40ca-a5ef-76b614490816",
   "metadata": {},
   "source": [
    "The old one: We only have so much gradient. Some of the gradient goes the alpha because it's one of 4 things it can optimize. So, because the alpha is helping to optimize the image where it's important, it clears out that alpha region first. Then this leads to a vicious cycle where the blocked areas aren't optimized and therefore its not safe to uncover them. this happens until the below image becomes palatable by chance.\n",
    "\n",
    "Todo: two way occlusion. Then, things like \"stuck in the bathtub\" can occlude a part of the foreground as well. OR we could solve this by having two layers...sandwiching the foreground..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ec7b35-00c7-4ec8-beb3-205a09d1f5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rp\n",
    "\n",
    "import nerf.sd as sd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from ryan.source.learnable_textures import LearnableTexturePackRaster,LearnableTexturePackFourier\n",
    "from ryan.source.learnable_textures import LearnableImageRaster,LearnableImageFourier\n",
    "import icecream\n",
    "import itertools\n",
    "from IPython.display import clear_output\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3ad4a1-e8b2-4db6-ba6e-cb4da32fb97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 's' not in dir():\n",
    "    s=sd.StableDiffusion('cuda')\n",
    "    # s=sd.StableDiffusion('cuda',\"nitrosocke/Arcane-Diffusion\")\n",
    "    # s=sd.StableDiffusion('cuda',\"/home/ryan/CleanCode/Datasets/models/stable_diffusion/v1_4/dreambooths/dreambooth-kurokiyousei-2000step-1666174076529\")\n",
    "device=s.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6c3951-ef60-4028-afe0-1a674315dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts=[\n",
    "    # \"beautiful sks jinx, Greg Rutkowski, ilya kuvshinov,artgerm highly detailed, flat stomach, hourglass figure\"\n",
    "    \"arcane style, jinx\"\n",
    "    # \"kurokiyousei\"\n",
    "]*5\n",
    "for prompt in prompts:\n",
    "    print(prompt)\n",
    "    img=s.prompt_to_img(prompt)[0]\n",
    "    rp.display_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5ce733-13cf-4a52-8459-8ab7875e4568",
   "metadata": {},
   "outputs": [],
   "source": [
    "img[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6049e454-d398-4367-8ade-7673aee34778",
   "metadata": {},
   "outputs": [],
   "source": [
    "height=width=128\n",
    "\n",
    "def make_learnable_image(num_channels):\n",
    "    return LearnableImageFourier(height,width,num_channels,num_features=512)\n",
    "    \n",
    "def composite_images(bottom,top,alpha):\n",
    "    return alpha*top+(1-alpha)*bottom\n",
    "\n",
    "class LearnableImageRGBA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.image=make_learnable_image(4)\n",
    "        \n",
    "    def forward(self):\n",
    "        image=self.image()\n",
    "        assert image.shape==(4,height,width)\n",
    "        rgb=image[:3]\n",
    "        alpha=image[3:]\n",
    "        assert rgb.shape  ==(3,height,width)\n",
    "        assert alpha.shape==(1,height,width)\n",
    "        alpha=alpha.repeat(3,1,1)\n",
    "        assert alpha.shape==rgb.shape==(3,height,width)\n",
    "        return rgb,alpha\n",
    "    \n",
    "class LearnableImageRGB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.image=make_learnable_image(3)\n",
    "        \n",
    "    def forward(self):\n",
    "        rgb=self.image()\n",
    "        assert rgb.shape  ==(3,height,width)\n",
    "        return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621d2c9d-d9cf-4592-9369-4403a2a46b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cartridge: First attempt!\n",
    "prompt_sections = [\n",
    "    [\n",
    "        # # 'danny devito',\n",
    "        # 'mario',\n",
    "        # 'a cute puppy',\n",
    "        'arcane style, a violin',\n",
    "        # 'an amethyst crystal',\n",
    "        # # 'pikachu',\n",
    "        # # 'a rubiks cube',\n",
    "        # 'a spooky skeleton',\n",
    "        # 'hatsune miku',\n",
    "        # # 'a tesla car',\n",
    "        # 'a steamboat',\n",
    "        'arcane style, a mermaid',\n",
    "        # 'a photo of a bananna',\n",
    "        # 'an astronaut riding a horse',\n",
    "        # 'a lolita outfit',\n",
    "        # # 'a cactus',\n",
    "        # # 'a campfire',\n",
    "        # # 'a teddy bear',\n",
    "        'arcane style, a bulldozer',\n",
    "        'arcane style, a nuclear blast mushroom cloud',\n",
    "        # 'a cute anime girl',\n",
    "        'arcane style, 3d emoji of sans from undertale',\n",
    "        # 'emma watson',\n",
    "        # 'emma watson',\n",
    "        # 'emma watson',\n",
    "        # 'emma watson',\n",
    "        # 'emma watson',\n",
    "        # 'emma watson',\n",
    "        # 'emma watson',\n",
    "        # 'emma watson',\n",
    "        # 'emma watson',\n",
    "        # 'emma watson',\n",
    "        'arcane style, shrek shrek shrek',\n",
    "        'arcane style, danny devito',\n",
    "        'arcane style, hatsune miku',\n",
    "        'arcane style, a 3d anime girl',\n",
    "        'arcane style, a 3d anime boy',\n",
    "        'arcane style, a mushroom man',\n",
    "        'arcane style, spaghetti and meatballs',\n",
    "        'arcane style, a 3d pixar woman',\n",
    "        'arcane style, a 3d pixar man',\n",
    "        'arcane style, jean luc picard',\n",
    "        # 'arcane style, emma watson',\n",
    "        'arcane style, sonic the hedgehog',\n",
    "        'arcane style, darth vader',\n",
    "        'arcane style, a cute dog',\n",
    "        'arcane style, a teddy bear',\n",
    "        'arcane style, a cat',\n",
    "        'arcane style, two spooky skeletons kissing',\n",
    "        'arcane style, emma watson holding a puppy',\n",
    "        'arcane style, jinx',\n",
    "    ],\n",
    "    [\n",
    "        # # '',\n",
    "        # # # 'floating in deep space',\n",
    "        'in the backrooms',\n",
    "        'in outer space',\n",
    "        'in the living room',\n",
    "        # # # 'in a suit of armor',\n",
    "        'on the front lawn',\n",
    "        'stuck in the bathtub',\n",
    "        'in a wooden wheelbarrow',\n",
    "        'in an old stone castle',\n",
    "        'in a fish tank',\n",
    "        'in times square',\n",
    "        'burning in hell',\n",
    "        'in a flying saucer',\n",
    "        'in a corn field',\n",
    "        'on a boat',\n",
    "        'in the desert',\n",
    "        'on mars',\n",
    "        'in a deep cave',\n",
    "        # 'riding a horse',\n",
    "        \n",
    "#         'wearing a tin foil hat',\n",
    "#         'wearing a tophat',\n",
    "#         'wearing a baseball cap',\n",
    "#         'wearing a witch hat',\n",
    "#         'wearing a biking helmet',\n",
    "#         'wearing a bandana',\n",
    "        # 'wearing a blonde wig',\n",
    "        \n",
    "        # 'eating a burger',\n",
    "        # 'eating a hogie',\n",
    "        # 'eating a slice of pizza',\n",
    "        # 'drinking a glass of water',\n",
    "        # 'drinking from a water bottle',\n",
    "        # 'drinking a glass of wine',\n",
    "        # 'eating a lollipop',\n",
    "        # 'eating a bananna',\n",
    "        # 'eating a pretzel',\n",
    "        \n",
    "        # # 'wearing a white roman toga',\n",
    "        # 'wearing a lolita dress',\n",
    "        # 'wearing a blue t-shirt',\n",
    "        # 'wearing a striped wool sweater',\n",
    "        # 'wearing a chrome suit of armor',\n",
    "        # 'wearing a button down t-shirt',\n",
    "        # # 'wearing a yellow hazmat suit',\n",
    "        # 'in a miniskirt',\n",
    "        # 'covered in spiders',\n",
    "        # 'in blue overalls',\n",
    "        # 'wearing a blonde wig',\n",
    "        # 'wearing a pointy hat',\n",
    "        # 'in a bath robe',\n",
    "        # # 'holding a sword',/\n",
    "        # # 'holding a frying pan',\n",
    "        # # 'eating cheese',\n",
    "    ],\n",
    "]\n",
    "\n",
    "REVERSE=True #Swap what is background for what is foreground without altering the prompts.\n",
    "REVERSE=False\n",
    "prompt_structure = '%s %s'\n",
    "\n",
    "if not REVERSE:\n",
    "\n",
    "    prompts = [prompt_structure%sections for sections in itertools.product(*prompt_sections)]\n",
    "    \n",
    "else:\n",
    "    prompt_sections=prompt_sections[::-1]\n",
    "    prompts = [prompt_structure%sections[::-1] for sections in itertools.product(*prompt_sections)]\n",
    "\n",
    "foreground_prompts, background_prompts = prompt_sections\n",
    "TRAIN_BACK=False #Should we train the backgrounds alone? (Yes leads to better performance - no is for asking interesting ablation questions)\n",
    "TRAIN_BACK=True \n",
    "\n",
    "old_prompts=list(prompts)\n",
    "# prompts += foreground_prompts\n",
    "prompts += background_prompts\n",
    "num_singles = len(prompts)-len(old_prompts)\n",
    "\n",
    "\n",
    "icecream.ic(prompts);\n",
    "text_embeddings=[s.get_text_embeddings(prompt) for prompt in prompts]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "images_foregrounds=[LearnableImageRGBA().to(device) for _ in prompt_sections[0]]\n",
    "images_backgrounds=[LearnableImageRGB ().to(device) for _ in prompt_sections[1]]\n",
    "\n",
    "all_images=images_foregrounds+images_backgrounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336872e1-2ae6-4b69-99e0-5913bbff084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(include_fb=False):\n",
    "    foregrounds=[x() for x in images_foregrounds]\n",
    "    backgrounds=[x() for x in images_backgrounds]\n",
    "    \n",
    "    composites=[composite_images(f,b,ɑ) for (f,ɑ),b in itertools.product(foregrounds,backgrounds)]\n",
    "    \n",
    "    composites += backgrounds\n",
    "    # composites += [x[0] for x in foregrounds]\n",
    "        \n",
    "    if include_fb:\n",
    "        return composites,foregrounds,backgrounds\n",
    "    else:\n",
    "        return composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0afa019-9b9b-4bbe-9334-0344606f1ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimgs=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819d56a4-e65d-436c-925f-49685e841cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def do_display(iter_num=None):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        date_string=rp.r._format_datetime(rp.get_current_date())[4:]#Get rid of 'Tue ' or 'Wed ' etc\n",
    "        stats_string=\"\"\"gradient_mixer.ipynb\\n%s\\niter_num: %i \\nLEARNING_RATE: %.1E\\nALPHA_HATE: %.1E \\nTRAIN_BACK: %s \\nREVERSE: %s\\nBATCH_SIZE: %i\"\"\".strip()%\\\n",
    "            (date_string, iter_num, LEARNING_RATE, ALPHA_HATE, TRAIN_BACK, REVERSE, BATCH_SIZE)\n",
    "        stats_string=rp.cv_text_to_image(stats_string,scale=.5)\n",
    "        stats_string = rp.cv_resize_image(stats_string,2/3)\n",
    "        \n",
    "        imgs,f,b=get_images(include_fb=True)\n",
    "        f,ɑ=zip(*f)\n",
    "        imgs=rp.as_numpy_images(torch.stack(imgs))\n",
    "        f=rp.as_numpy_images(torch.stack(f))\n",
    "        ɑ=1-rp.as_numpy_images(torch.stack(ɑ))\n",
    "        b=rp.as_numpy_images(torch.stack(b))\n",
    "        \n",
    "        \n",
    "        #Add borders to each image\n",
    "        def borderize(img):\n",
    "            return rp.bordered_image_solid_color(img,color=(0,0,0,0),thickness=0,bottom=1,right=1)\n",
    "        f=list(map(borderize,f))\n",
    "        ɑ=list(map(borderize,ɑ))\n",
    "        b=list(map(borderize,b))\n",
    "        imgs=list(map(borderize,imgs))\n",
    "        \n",
    "        \n",
    "        def labeled_images(images,labels,position='top',just_labels=False):\n",
    "            if just_labels:\n",
    "                images=[image[0:1,:]*0 for image in images]#Make them all lines...we just want the labels\n",
    "            colors=[(200,250,250),(250,250,200),(250,200,250)]\n",
    "            text_width=10\n",
    "            wrapped_labels=[rp.line_join(textwrap.wrap(label,text_width)) for label in labels]\n",
    "            num_lines=max(rp.number_of_lines(x) for x in wrapped_labels)\n",
    "            wrapped_labels=['\\n'*(num_lines-rp.number_of_lines(x))+x for x in wrapped_labels]\n",
    "            return [rp.labeled_image(images[i],\n",
    "                                     wrapped_labels[i],\n",
    "                                     size=15*rp.number_of_lines(wrapped_labels[i]),\n",
    "                                     position=position,\n",
    "                                     text_color=colors[i%len(colors)])\n",
    "                    for i in range(len(labels))],num_lines\n",
    "        \n",
    "        # top_dimg=rp.tiled_images(rp.list_pop(list(zip(*rp.split_into_sublists(imgs[:-num_singles],len(images_backgrounds))))),length=len(images_foregrounds))\n",
    "        # top_dimg=rp.tiled_images(rp.list_pop(list(zip(*rp.split_into_sublists(imgs[:-num_singles],len(images_backgrounds))))),length=len(images_foregrounds))\n",
    "        imggrid=list(zip(*rp.split_into_sublists(imgs[:-num_singles],len(images_backgrounds))))\n",
    "        imggrid=list(map(list,imggrid))\n",
    "        singles=imgs[-num_singles:]\n",
    "        singles,num_bg_lines=labeled_images(singles,background_prompts,position='left')\n",
    "        for i,single in enumerate(singles):\n",
    "            imggrid[i].insert(0,single)\n",
    "\n",
    "\n",
    "        # top_dimg=rp.tiled_images(imgs[:-num_singles],length=len(images_backgrounds))\n",
    "        # bot_dimg=rp.tiled_images(imgs[-num_singles:])\n",
    "        blank_image=rp.as_numpy_array([[0.0]])\n",
    "        blank_image=rp.uniform_float_color_image(height,width,color=(0,0,0,0))\n",
    "        ɑ_labels,_=labeled_images(ɑ,foreground_prompts,just_labels=True)\n",
    "\n",
    "        imggrid.insert(0,[\n",
    "            rp.labeled_image(\n",
    "                rp.labeled_image( blank_image[15:], 'Back  ' ,text_color=(255,128 if TRAIN_BACK else 0,0),position='bottom', size=15,align='right'),\n",
    "                '\\n'*(num_bg_lines-1)+'Front'  ,size=15*num_bg_lines,text_color=(255,0,0),position='right',flip_text=True)\n",
    "        ]+list(f))\n",
    "        imggrid.insert(0,[rp.labeled_image(blank_image,'\\n'*(num_bg_lines-1)+'Alpha',size=15*num_bg_lines,text_color=(255,128 if ALPHA_HATE else 0,0),position='right',flip_text=True)]+list(ɑ))\n",
    "        imggrid.insert(0,[blank_image[0:1,0:1]]+list(ɑ_labels))\n",
    "        # mggrid.insert(0,[blank_image+list(ɑ))\n",
    "        dimg=rp.grid_concatenated_images(imggrid)\n",
    "        \n",
    "        # extras=rp.horizontally_concatenated_images(ɑ)\n",
    "        # dimg=rp.vertically_concatenated_images(extras,dimg)\n",
    "        dimg=rp.blend_images(dimg,stats_string,stats_string*1/2)\n",
    "        \n",
    "        dimgs.append(dimg)\n",
    "        rp.display_image(dimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf069fe-2163-4033-89d8-7541367548c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dimgs.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a1948a-86dd-4abc-b590-7887d2039d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_num=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71f869-62ad-4a23-b0e8-a91e9a3bd4b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params=list(itertools.chain(*(x.parameters() for x in all_images)))\n",
    "icecream.ic(len(params),TRAIN_BACK,num_singles)\n",
    "\n",
    "LEARNING_RATE=1e-3/5\n",
    "\n",
    "optim=torch.optim.Adam(params,lr=1e-3/5)#For fourier. 1e-2 is too high.\n",
    "# optim=torch.optim.Adam(params,lr=1e-2)#Normally this is too high, as the colors start to get too strong...but in this case, we want a binary mask anyway lol - might as well do it the fast way!\n",
    "# optim=torch.optim.Adam(params,lr=1e-2/5)#Normally this is too high, as the colors start to get too strong...but in this case, we want a binary mask anyway lol - might as well do it the fast way!\n",
    "# optim=torch.optim.Adam(params,lr=1e-1)#For raster. \n",
    "# optim=torch.optim.SGD(params,lr=1e-1)#For raster\n",
    "# optim=torch.optim.SGD(params,lr=1e-5)#For raster\n",
    "\n",
    "ALPHA_HATE=1e-2 #If this is true, we hate alpha! We want it to be transparent\n",
    "# ALPHA_HATE=1e-1 #If this is true, we hate alpha! We want it to be transparent\n",
    "ALPHA_HATE=False\n",
    "\n",
    "BATCH_SIZE=5\n",
    "BATCH_SIZE=10\n",
    "\n",
    "display_eta=rp.eta(1000000)\n",
    "\n",
    "for _ in range(1000000):\n",
    "    __=_\n",
    "    _=iter_num\n",
    "    iter_num+=1\n",
    "    display_eta(_)\n",
    "    \n",
    "    \n",
    "    imgs,f,b=get_images(include_fb=True)\n",
    "    if not TRAIN_BACK:\n",
    "        imgs=imgs[:-num_singles]\n",
    "    \n",
    "    f,a=zip(*f)\n",
    "    batch=list(zip(text_embeddings,imgs))\n",
    "    \n",
    "    if ALPHA_HATE:\n",
    "        (-torch.stack(a).sum()*ALPHA_HATE).backward(retain_graph=True) #Alpha pushback loss. unbalanced;varies with num imgs\n",
    "    \n",
    "    # batch_size=5\n",
    "    # batch_size=5 #I'm going to sleep...I'll let this run overnight. This batch size is overkill tho\n",
    "    \n",
    "    mini_batch = rp.random_batch(batch,min(BATCH_SIZE,len(batch)))\n",
    "    \n",
    "    for embed,image in mini_batch:\n",
    "        s.train_step(embed,image[None],by_loss=False)\n",
    "        \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if _ and not _%500:\n",
    "            clear_output()\n",
    "            # rp.display_image_slideshow(dimgs)\n",
    "        if not _%50 or not __:\n",
    "            do_display(iter_num)\n",
    "\n",
    "    optim.step()\n",
    "    optim.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251aa09e-f23a-4375-82a0-b151d807914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.display_image(dimgs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85309ed-754e-433b-b1c5-60e0c3b04910",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.display_image_slideshow(dimgs,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c762739-1d45-4977-8d27-59f44ce621d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.display_image_slideshow(dimgs[::20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2373369c-3a61-46f4-9f76-a06ab25d8e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6b8717-c49b-48d3-87ef-6d55de0cce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.display_image_slideshow(dimgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b078352-885a-4014-a53c-c8c9cb78431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51e7465-af77-49e8-965a-3ea8a3d39f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.display_image_slideshow(dimgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2830a0-3785-4ca8-84f2-88f88e93cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.display_image_slideshow(dimgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543dc704-6556-4cff-9be8-644e92658cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.display_image_slideshow(dimgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72318e96-bbf0-4379-b8b5-4c29ea2c4e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.display_image_slideshow(dimgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2aa9e9-3284-4142-a590-65c2a85f7011",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.display_image_slideshow(dimgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aeba5a-0daa-4164-9afd-219f0c787a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.display_image_slideshow(dimgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdcbf68-a748-4cb4-9c65-432620b76a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.display_image_slideshow(dimgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0878b8f2-6085-424e-9581-ac59bb8ed95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.display_image_slideshow(dimgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d5815a-1e8a-430b-9b68-220ab3868de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.display_image_slideshow(dimgs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
