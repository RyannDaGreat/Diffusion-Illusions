{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:   \n",
    "  try:\n",
    "    import random\n",
    "    # random.seed(SEED)\n",
    "    \n",
    "    import numpy as np\n",
    "    import rp\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import source.stable_diffusion as sd\n",
    "    from easydict import EasyDict\n",
    "    from source.learnable_textures import LearnableImageFourier, LearnableImageRasterSigmoided\n",
    "    from source.stable_diffusion_labels import NegativeLabel\n",
    "    from itertools import chain\n",
    "    import torch.nn as nn\n",
    "    import time\n",
    "    \n",
    "    start_time=rp.gtoc()\n",
    "    \n",
    "    print(\"NEW BOREALIS\")\n",
    "    \n",
    "    HEADLESS = 'HEADLESS' in vars() and HEADLESS #This is set to True when we run this headless. And, if this cell is run twice, it will STILL be false!\n",
    "    print(\"HEADLESS:\",HEADLESS)\n",
    "    \n",
    "    random_prompt_sets=[['a beautiful award-winning royalty-free full-frame stock photo of an isolated horse', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bottle', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated dog', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated sofa', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated television'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated cat', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated dining table', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated car', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated aeroplane', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated sheep'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated cow', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated motorbike', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated chair', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated train', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bird'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated motorbike', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated train', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bus', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated television', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated dog'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated train', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated person', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated sheep', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated dining table', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated sofa'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated potted plant', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated horse', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bicycle', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated motorbike', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated cat'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated boat', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated dog', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated dining table', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bus', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated cow'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated bottle', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated television', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated motorbike', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated cat', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bicycle'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated dining table', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated aeroplane', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated horse', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated boat', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated motorbike'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated bird', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated car', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated cat', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated horse', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated person'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated chair', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bird', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated television', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated dog', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated aeroplane'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated car', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated cat', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bird', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bottle', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated horse'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated sofa', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated boat', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated potted plant', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated person', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated chair'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated bicycle', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated chair', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated train', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated sheep', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated boat'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated bus', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated cow', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated boat', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated car', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated potted plant'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated person', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bicycle', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bottle', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bird', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bus'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated aeroplane', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated sheep', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated cow', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated chair', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated car'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated dog', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated sofa', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated aeroplane', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated potted plant', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bottle'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated sheep', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bus', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated person', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bicycle', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated train'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated television', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated potted plant', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated sofa', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated cow', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated dining table']]\n",
    "    \n",
    "    if True:# and not HEADLESS and 'prompt_a' not in vars():\n",
    "        #ONLY GOOD PROMPTS HERE\n",
    "        prompt_structure='MANUAL_PROMPT_STRUCT'\n",
    "        example_prompts = rp.load_yaml_file('source/example_prompts.yaml')\n",
    "        print('Available example prompts:', ', '.join(example_prompts))\n",
    "        \n",
    "        # title='lipstick volcano porche kitten_in_box picard'\n",
    "        # title='thomas_tank_military thomas_tank_military thomas_tank_military thomas_tank_military walter_white'\n",
    "        title='froggo froggo froggo froggo porche'\n",
    "        title='lipstick lipstick lipstick lipstick gandalf'\n",
    "        title='miku miku miku miku picard'\n",
    "        title='miku miku miku miku pyramids'\n",
    "        title='stormtrooper stormtrooper stormtrooper stormtrooper fire_magic_girl'\n",
    "        title = 'gandalf gandalf gandalf gandalf miku' \n",
    "        title='miku froggo lipstick kitten_in_box darth_vader'\n",
    "        #These prompts are all strings - you can replace them with whatever you want! By default it lets you choose from example prompts\n",
    "        title='pyramids pyramids pyramids pyramids miku'\n",
    "        title='pencil_cow pencil_penguin pencil_dog_head pencil_giraffe_head pencil_cat_head'\n",
    "        title='victorial_dress winter summer kitten_in_box froggo'\n",
    "        title='miku miku miku miku picard'\n",
    "        title='miku froggo picard victorial_dress victorial_dress'\n",
    "        title='miku froggo picard victorial_dress victorial_dress'\n",
    "        # title='kitten_in_box kitten_in_box kitten_in_box kitten_in_box pikachu'\n",
    "        prompt_a, prompt_b, prompt_c, prompt_d, prompt_z = rp.gather(example_prompts, title.split())\n",
    "        \n",
    "        \n",
    "        #Prompts a,b,c,d are the normal looking images\n",
    "        #Prompt z is the hidden image you get when you overlay them all on top of each other\n",
    "        # prompt_a, prompt_b, prompt_c, prompt_d, prompt_z = [*(['happy puppies']*4),'the word \"HELP!\"']\n",
    "        # prompt_a, prompt_b, prompt_c, prompt_d, prompt_z = ['cute anime boy','cute anime girl','cute anime dog','cute anime cat','the word \"DANGER!\"']\n",
    "        # prompt_a, prompt_b, prompt_c, prompt_d, prompt_z = ['photo of astronaut in space','a 3d photo of a beautiful spaceship fighter craft sleek','beautiful photo of planets with rings','a beautiful photo of the moon','nyan cat']\n",
    "        \n",
    "        \n",
    "        # prompt_a, prompt_b, prompt_c, prompt_d, prompt_z = [*['a beautiful award-winning photograph of a phd student reading papers','a beautiful photograph a student working on a laptop','national geographic photo of seagulls eating fries at the dock','a portrait of a photo of a phd student reading papers'],'this is fine dog in fire']\n",
    "        # prompt_a, prompt_b, prompt_c, prompt_d, prompt_z = [*(['a playground with a swingset and slides']*4),'the word \"DANGER!\"']\n",
    "        # prompt_a, prompt_b, prompt_c, prompt_d, prompt_z = [*(['a photo of the deep jungle']*4),'the word \"DANGER!\"']\n",
    "    \n",
    "    \n",
    "    #     prompt_a,prompt_z = 'dreamworks 3d rendering of puss in boots', 'dreamworks 3d rendering of shrek'\n",
    "    #     prompt_a,prompt_b,prompt_c,prompt_d,prompt_z=['an intricate detailed hb pencil sketch of a %s'%x.strip() for x in 'dog head, girl head, boy head, tree, cat head'.split(',')]\n",
    "    \n",
    "    \n",
    "        \n",
    "        prompt_a,prompt_b,prompt_c,prompt_d,prompt_z=(\n",
    "        'a beautiful award-winning royalty-free full-frame stock photo of an isolated sheep',\n",
    "        'a beautiful award-winning royalty-free full-frame stock photo of an isolated bus',\n",
    "        'a beautiful award-winning royalty-free full-frame stock photo of an isolated sofa',\n",
    "        'a beautiful award-winning royalty-free full-frame stock photo of an isolated potted plant',\n",
    "        'a beautiful award-winning royalty-free full-frame stock photo of an isolated dog',\n",
    "    )\n",
    "        # prompt_a,prompt_b,prompt_c,prompt_d,prompt_z=['an intricate detailed hb pencil sketch of a %s'%x.strip() for x in 'spotted cow, penguin, dog head, giraffe head, cat head'.split(',')]\n",
    "    \n",
    "    \n",
    "        prompt_a,prompt_b,prompt_c,prompt_d,prompt_z=(\n",
    "        '3d render of a parrot',\n",
    "        '3d render of an airplane',\n",
    "        '3d render of super man',\n",
    "        '3d render of a nasa space shuttle',\n",
    "        'a beautiful award-winning royalty-free full-frame stock photo of an isolated potted plant',\n",
    "    )\n",
    "        # prompt_c=\"an intricate detailed hb pencil sketch of a puppy dog bichon head\"\n",
    "        # SK='hb pencil sketch'\n",
    "        # CO='photorealistic color oil painting'\n",
    "        # prompt_a=prompt_a.replace(SK,CO)\n",
    "        # prompt_b=prompt_b.replace(SK,CO)\n",
    "        # prompt_c=prompt_c.replace(SK,CO)\n",
    "        # prompt_d=prompt_d.replace(SK,CO)\n",
    "        # prompt_z=prompt_z.replace(SK,CO)\n",
    "        random_prompt_sets=[['a beautiful award-winning royalty-free full-frame stock photo of an isolated horse', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bottle', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated dog', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated sofa', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated television'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated cat', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated dining table', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated car', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated aeroplane', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated sheep'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated cow', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated motorbike', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated chair', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated train', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bird'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated motorbike', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated train', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bus', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated television', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated dog'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated train', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated person', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated sheep', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated dining table', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated sofa'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated potted plant', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated horse', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bicycle', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated motorbike', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated cat'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated boat', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated dog', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated dining table', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bus', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated cow'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated bottle', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated television', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated motorbike', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated cat', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bicycle'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated dining table', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated aeroplane', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated horse', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated boat', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated motorbike'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated bird', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated car', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated cat', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated horse', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated person'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated chair', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bird', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated television', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated dog', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated aeroplane'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated car', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated cat', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bird', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bottle', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated horse'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated sofa', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated boat', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated potted plant', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated person', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated chair'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated bicycle', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated chair', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated train', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated sheep', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated boat'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated bus', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated cow', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated boat', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated car', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated potted plant'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated person', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bicycle', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bottle', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bird', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bus'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated aeroplane', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated sheep', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated cow', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated chair', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated car'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated dog', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated sofa', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated aeroplane', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated potted plant', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bottle'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated sheep', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bus', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated person', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated bicycle', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated train'], ['a beautiful award-winning royalty-free full-frame stock photo of an isolated television', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated potted plant', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated sofa', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated cow', 'a beautiful award-winning royalty-free full-frame stock photo of an isolated dining table']]\n",
    "        \n",
    "        ranprom=rp.gather(example_prompts,['pwkitten_in_box','emma_watson','yorkshire_terrier_santa','norwegian_winter_girl','victorial_dress','pencil_giraffe_head','pencil_penguin','pencil_violin','pencil_orca_whale','pencil_cow','pencil_walrus','pencil_cat_head','pencil_dog_head','ape_with_gun','human_skeleton','mario','burger','darth_vader','gandalf','fantasy_city','miku','picard','minecraft_zombie','volcano','porche','hawaii_beach','donut','sushi','icecream','strawberry','anime_bunny','anime_girl_under_stars','majestic_golden_retriever','playful_tabby_cat','regal_deer_in_mist','wise_old_owl','graceful_swimming_dolphin','sleepy_panda_in_bamboo_grove','proud_lion_king','curious_raccoon_in_urban_night','elegant_horse_in_meadow','fluttering_hummingbird_near_flower','loyal_border_collie_herd','mysterious_fox_in_snow','playful_sea_otter_with_shell','majestic_bald_eagle_flight','gentle_giraffe_in_savannah','fuzzy_baby_penguin_in_snow','majestic_peacock_displaying_feathers','curious_squirrel_in_autumn_park','wizard','leprechaun','dragon','sphinx','sonic_the_hedgehog','yoda','link','kraken','masculine_man','makeup_woman','dog_face','cat_face','rat_face','ice_cream_cone','hamburger','spaghetti','french_fries','donut','chicken_nuggets','coffee','milk','croissant','fried_egg','pizza_slice','chocolate','pancake_stack','meatball','meatball','monkey_tophat','eiffel_tower','pyramids_of_giza','statue_of_liberty','golden_gate_bridge','leaning_tower_of_pisa','stonehenge','sydney_opera_house','times_square','mount_fuji','longsword','crossbow','bow_and_arrow'])\n",
    "        random_prompt_sets=random_prompt_sets+[rp.random_batch(ranprom,5) for x in range(len(random_prompt_sets))]\n",
    "        \n",
    "        prompt_a,prompt_b,prompt_c,prompt_d,prompt_z=rp.random_element(random_prompt_sets)\n",
    "    \n",
    "    \n",
    "    negative_prompt = 'blurry'\n",
    "    \n",
    "    print()\n",
    "    print('Negative prompt:',repr(negative_prompt))\n",
    "    print()\n",
    "    print('Chosen prompts:')\n",
    "    print('    prompt_a =', repr(prompt_a))\n",
    "    print('    prompt_b =', repr(prompt_b))\n",
    "    print('    prompt_c =', repr(prompt_c))\n",
    "    print('    prompt_d =', repr(prompt_d))\n",
    "    print('    prompt_z =', repr(prompt_z))\n",
    "    \n",
    "    TYPE='HIDDEN';BACKLIGHT_FACTOR=6 #'FLIPPY', 'ROTATOR', 'HIDDEN'\n",
    "    # TYPE='ROTATOR';BACKLIGHT_FACTOR=2 #'FLIPPY', 'ROTATOR', 'HIDDEN'\n",
    "    # TYPE='FLIPPY' #'FLIPPY', 'ROTATOR', 'HIDDEN'\n",
    "    if not HEADLESS:\n",
    "        BIG=True\n",
    "        BIG=False\n",
    "    \n",
    "        if 'USE_SDXL' not in vars():\n",
    "            USE_SDXL=True\n",
    "            # USE_SDXL=False\n",
    "    \n",
    "        if 'SAVE_DIR' not in vars():\n",
    "            SAVE_DIR='SIGG_REBUTTAL_HIDDEN'\n",
    "    \n",
    "        SAVE_TITLE=SAVE_DIR+'$'+'_'.join([\n",
    "            prompt_a[-20:],\n",
    "            prompt_b[-20:],\n",
    "            prompt_c[-20:],\n",
    "            prompt_d[-20:],\n",
    "            prompt_z[-20:],\n",
    "        ])+'$'+prompt_structure\n",
    "        \n",
    "        SDS_ITERS=1\n",
    "        \n",
    "        gpu=rp.select_torch_device() if 'gpu' not in vars() else gpu\n",
    "    \n",
    "        #FOR SDS\n",
    "        print(\"IUHAIUHSDIUHASHIUDALIUHSDHILUASLHIUALHISUHILU\")\n",
    "        model_name=\"CompVis/stable-diffusion-v1-4\"  if 'model_name' not in vars() else model_name\n",
    "    \n",
    "        SEED=int(rp.gtoc())\n",
    "    \n",
    "        AUTO_WEIGHT=True\n",
    "    \n",
    "    if 's' not in dir():\n",
    "        # model_name=\n",
    "        s=sd.StableDiffusion(gpu,model_name)\n",
    "    device=s.device\n",
    "    \n",
    "    label_a = NegativeLabel(prompt_a,negative_prompt)\n",
    "    label_b = NegativeLabel(prompt_b,negative_prompt)\n",
    "    label_c = NegativeLabel(prompt_c,negative_prompt)\n",
    "    label_d = NegativeLabel(prompt_d,negative_prompt)\n",
    "    label_z = NegativeLabel(prompt_z,negative_prompt)\n",
    "    \n",
    "    CLEAN_MODE = True # If it's False, we augment the images by randomly simulating how good a random printer might be when making the overlays...\n",
    "    RANDOM_SHIFT=True\n",
    "    def simulate_overlay(a,b,c=1,d=1):\n",
    "        if CLEAN_MODE:\n",
    "            if PARAM=='RASTER' and RANDOM_SHIFT:\n",
    "                for _ in range(3):\n",
    "                    #Random gaussian shifting to prevent pixelation issues\n",
    "                    if hasattr(a,'roll'):a=a.roll(rp.random_int(-1,1),1).roll(rp.random_int(-1,1),2)\n",
    "                    if hasattr(b,'roll'):b=b.roll(rp.random_int(-1,1),1).roll(rp.random_int(-1,1),2)\n",
    "                    if hasattr(c,'roll'):c=c.roll(rp.random_int(-1,1),1).roll(rp.random_int(-1,1),2)\n",
    "                    if hasattr(d,'roll'):d=d.roll(rp.random_int(-1,1),1).roll(rp.random_int(-1,1),2)\n",
    "    \n",
    "            exp=1\n",
    "            brightness=BACKLIGHT_FACTOR\n",
    "            black=0\n",
    "        else:\n",
    "            exp=rp.random_float(.5,1)\n",
    "            brightness=rp.random_float(1,5)\n",
    "            black=rp.random_float(0,.5)\n",
    "            bottom=rp.blend(bottom,black,rp.random_float())\n",
    "            top=rp.blend(top,black,rp.random_float())\n",
    "        return (a**exp * b**exp *c**exp * d**exp * brightness).clamp(0,1) #Better simulation\n",
    "        return (a**exp * b**exp *c**exp * d**exp * brightness).clamp(0,99).tanh()\n",
    "    \n",
    "    #Image Parametrization and Initialization (this section takes vram)\n",
    "    \n",
    "    #Select Learnable Image Size (this has big VRAM implications!):\n",
    "    #Note: We use implicit neural representations for better image quality\n",
    "    #They're previously used in our paper \"TRITON: Neural Neural Textures make Sim2Real Consistent\" (see tritonpaper.github.io)\n",
    "    # ... and that representation is based on Fourier Feature Networks (see bmild.github.io/fourfeat)\n",
    "    # num_prime_images=4\n",
    "    \n",
    "    # learnable_image_maker = lambda: LearnableImageFourier(height=256, width=256, hidden_dim=256, num_features=128, num_channels=3*num_prime_images).to(s.device); SIZE=256\n",
    "    # # learnable_image_maker = lambda: LearnableImageFourier(height=384,width=384,num_features=256,hidden_dim=256,scale=15).to(s.device);SIZE=384\n",
    "    # # learnable_image_maker = lambda: LearnableImageFourier(height=512,width=512,num_features=256,hidden_dim=256,scale=20).to(s.device);SIZE=512\n",
    "    \n",
    "    # image_a=lambda: learnable_image_maker()[0:3]# learnable_image_maker()\n",
    "    # image_b=lambda: learnable_image_maker()[3:6]# learnable_image_maker()\n",
    "    # image_c=lambda: learnable_image_maker()[6:9]# learnable_image_maker()\n",
    "    # image_d=lambda: learnable_image_maker()[9:12]# learnable_image_maker()\n",
    "    \n",
    "    PARAM='RASTER'\n",
    "    # PARAM='FOURIER'\n",
    "    \n",
    "    def learnable_image_factory(self):\n",
    "        if PARAM=='FOURIER':\n",
    "            return LearnableImageFourier(\n",
    "                height=self.SIZE,\n",
    "                width=self.SIZE,\n",
    "                hidden_dim=256,\n",
    "                num_features=256 if BIG else 128,\n",
    "                num_channels=3,\n",
    "                scale=15 if BIG else 10,\n",
    "            )\n",
    "        elif PARAM=='RASTER':\n",
    "            return LearnableImageRasterSigmoided(\n",
    "                height=self.SIZE ,\n",
    "                width=self.SIZE,\n",
    "                num_channels=3,\n",
    "            )\n",
    "        else:\n",
    "            assert False, PARAM\n",
    "    \n",
    "    \n",
    "    class Invalidatable:\n",
    "        def __init__(self, get):\n",
    "            self.get=get\n",
    "            self._cache=None\n",
    "            self._valid=False\n",
    "        def __call__(self):\n",
    "            if not self._valid:\n",
    "                self._cache=self.get()\n",
    "                self._valid=True\n",
    "            return self._cache\n",
    "        def invalidate():\n",
    "            self._valid=False\n",
    "    \n",
    "    class LearnableImageBatch(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            \n",
    "            self.SIZE=512 if BIG else 256\n",
    "    \n",
    "            self._mega_image=LearnableImageFourier(\n",
    "                height=self.SIZE,\n",
    "                width=self.SIZE,\n",
    "                hidden_dim=256,\n",
    "                num_features=256 if BIG else 128,\n",
    "                num_channels=3*4,\n",
    "                scale=15 if BIG else 10,\n",
    "            )\n",
    "    \n",
    "            self._mega_image = self._mega_image\n",
    "            self._mega_image_cache = None\n",
    "    \n",
    "            self._images = [self.get_a, self.get_b, self.get_c, self.get_d, self.get_z]\n",
    "    \n",
    "            self.handled=[True, True, True, True, True]\n",
    "    \n",
    "        \n",
    "        def _get_mega_image(self, cached=False):\n",
    "            if not cached or self._mega_image_cache is None:\n",
    "                self._mega_image_cache = self._mega_image()\n",
    "            return self._mega_image_cache\n",
    "            \n",
    "        def _get_sub_image(self,index,cached=False):\n",
    "            #Use invalidation for big speed boost!\n",
    "            return self._get_mega_image(cached=cached)[index*3:(index+1)*3]\n",
    "            \n",
    "        def get_a(self,cached=False):return self._get_sub_image(0,cached=cached)\n",
    "        \n",
    "        def get_b(self,cached=False):return self._get_sub_image(1,cached=cached)\n",
    "            \n",
    "        def get_c(self,cached=False):return self._get_sub_image(2,cached=cached)    \n",
    "            \n",
    "        def get_d(self,cached=False):return self._get_sub_image(3,cached=cached)    \n",
    "    \n",
    "        def get_z(self,cached=False):\n",
    "            return simulate_overlay(\n",
    "                self.get_a(cached=cached), \n",
    "                self.get_b(cached=True), \n",
    "                self.get_c(cached=True), \n",
    "                self.get_d(cached=True),\n",
    "            )\n",
    "    \n",
    "        def __getitem__(self,index):\n",
    "            return self._images[index]\n",
    "            \n",
    "        def __len__(self):\n",
    "            return len(self._images)\n",
    "    \n",
    "    \n",
    "    \n",
    "    class IndependentLearnableImageBatch(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            \n",
    "            self.SIZE=512 if BIG else 256\n",
    "            self.SIZE*=dict(RASTER=2,FOURIER=1)[PARAM]\n",
    "    \n",
    "            self._primes=nn.ModuleList([\n",
    "                learnable_image_factory(self)\n",
    "                for x in range(4)\n",
    "            ])\n",
    "    \n",
    "            self.handled=[True, True, True, True, True]\n",
    "    \n",
    "    \n",
    "            self._mega_image_cache = None\n",
    "    \n",
    "            self._images = [self.get_a, self.get_b, self.get_c, self.get_d, self.get_z]\n",
    "            \n",
    "        def _get_sub_image(self,index,cached=False):\n",
    "            #Use invalidation for big speed boost!\n",
    "            return self._primes[index]()\n",
    "            \n",
    "        def get_a(self):return self._get_sub_image(0)\n",
    "        \n",
    "        def get_b(self):return self._get_sub_image(1)\n",
    "            \n",
    "        def get_c(self):return self._get_sub_image(2)    \n",
    "            \n",
    "        def get_d(self):return self._get_sub_image(3)    \n",
    "    \n",
    "        def get_z(self):\n",
    "            return simulate_overlay(\n",
    "                self.get_a(), \n",
    "                self.get_b(), \n",
    "                self.get_c(), \n",
    "                self.get_d(),\n",
    "            )\n",
    "    \n",
    "        def __getitem__(self,index):\n",
    "            return self._images[index]\n",
    "            \n",
    "        def __len__(self):\n",
    "            return len(self._images)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    class FlippyImageBatch(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            \n",
    "            self.SIZE=512 if BIG else 256\n",
    "            self.SIZE*=dict(RASTER=2,FOURIER=1)[PARAM]\n",
    "    \n",
    "            self._primes=nn.ModuleList([\n",
    "                learnable_image_factory(self)\n",
    "                for x in range(1)\n",
    "            ])\n",
    "    \n",
    "            self.handled=[True, False, False, False, True]\n",
    "            \n",
    "            self._mega_image_cache = None\n",
    "    \n",
    "            self._empty=self._get_empty().to(device)\n",
    "    \n",
    "            self._images = [self.get_a, self.get_b, self.get_c, self.get_d, self.get_z]\n",
    "    \n",
    "        def _get_empty(self):\n",
    "            #Instead of refactoring the code to take two images, I'll just nullify the others...\n",
    "            with torch.no_grad():\n",
    "                return torch.zeros(3,self.SIZE,self.SIZE)\n",
    "            \n",
    "        def _get_sub_image(self,index,cached=False):\n",
    "            #Use invalidation for big speed boost!\n",
    "            return self._primes[index]()\n",
    "            \n",
    "        def get_a(self):return self._get_sub_image(0)\n",
    "        \n",
    "        def get_b(self):return self._empty\n",
    "            \n",
    "        def get_c(self):return self._empty\n",
    "            \n",
    "        def get_d(self):return self._empty\n",
    "    \n",
    "        def get_z(self):return self.get_a().rot90(k=2,dims=[1,2]) #Upside-down\n",
    "    \n",
    "        def __getitem__(self,index):\n",
    "            return self._images[index]\n",
    "            \n",
    "        def __len__(self):\n",
    "            return len(self._images)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    class FlippyImageBatch(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            \n",
    "            self.SIZE=512 if BIG else 256\n",
    "            self.SIZE*=dict(RASTER=2,FOURIER=1)[PARAM]\n",
    "    \n",
    "            self._primes=nn.ModuleList([\n",
    "                learnable_image_factory(self)\n",
    "                for x in range(1)\n",
    "            ])\n",
    "    \n",
    "            self.handled=[True, False, False, False, True]\n",
    "            \n",
    "            self._mega_image_cache = None\n",
    "    \n",
    "            self._empty=self._get_empty().to(device)\n",
    "    \n",
    "            self._images = [self.get_a, self.get_b, self.get_c, self.get_d, self.get_z]\n",
    "    \n",
    "        def _get_empty(self):\n",
    "            #Instead of refactoring the code to take two images, I'll just nullify the others...\n",
    "            with torch.no_grad():\n",
    "                return torch.zeros(3,self.SIZE,self.SIZE)\n",
    "            \n",
    "        def _get_sub_image(self,index,cached=False):\n",
    "            #Use invalidation for big speed boost!\n",
    "            return self._primes[index]()\n",
    "            \n",
    "        def get_a(self):return self._get_sub_image(0)\n",
    "        \n",
    "        def get_b(self):return self._empty\n",
    "            \n",
    "        def get_c(self):return self._empty\n",
    "            \n",
    "        def get_d(self):return self._empty\n",
    "    \n",
    "        def get_z(self):return self.get_a().rot90(k=2,dims=[1,2]) #Upside-down\n",
    "    \n",
    "        def __getitem__(self,index):\n",
    "            return self._images[index]\n",
    "            \n",
    "        def __len__(self):\n",
    "            return len(self._images)\n",
    "    \n",
    "    \n",
    "    \n",
    "    class FlippyImageBatch(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            \n",
    "            self.SIZE=512 if BIG else 256\n",
    "            self.SIZE*=dict(RASTER=2,FOURIER=1)[PARAM]\n",
    "    \n",
    "            self._primes=nn.ModuleList([\n",
    "                learnable_image_factory(self)\n",
    "                for x in range(1)\n",
    "            ])\n",
    "    \n",
    "            self.handled=[True, True, True, True, False]\n",
    "            \n",
    "            self._mega_image_cache = None\n",
    "    \n",
    "            self._empty=self._get_empty().to(device)\n",
    "    \n",
    "            self._images = [self.get_a, self.get_b, self.get_c, self.get_d, self.get_z]\n",
    "    \n",
    "        def _get_empty(self):\n",
    "            #Instead of refactoring the code to take two images, I'll just nullify the others...\n",
    "            with torch.no_grad():\n",
    "                return torch.zeros(3,self.SIZE,self.SIZE)\n",
    "            \n",
    "        def _get_sub_image(self,index,cached=False):\n",
    "            #Use invalidation for big speed boost!\n",
    "            return self._primes[index]()\n",
    "            \n",
    "        def get_a(self):return self._get_sub_image(0)\n",
    "        \n",
    "        def get_b(self):return self._empty\n",
    "            \n",
    "        def get_c(self):return self._empty\n",
    "            \n",
    "        def get_d(self):return self._empty\n",
    "    \n",
    "        def get_z(self):return self.get_a().rot90(k=2,dims=[1,2]) #Upside-down\n",
    "    \n",
    "        def __getitem__(self,index):\n",
    "            return self._images[index]\n",
    "            \n",
    "        def __len__(self):\n",
    "            return len(self._images)\n",
    "    \n",
    "    \n",
    "    \n",
    "    class RotatorImageBatch(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            \n",
    "            self.SIZE=512 if BIG else 256\n",
    "            self.SIZE*=dict(RASTER=2,FOURIER=1)[PARAM]\n",
    "    \n",
    "            self._primes=nn.ModuleList([\n",
    "                learnable_image_factory(self)\n",
    "                for x in range(2)\n",
    "            ])\n",
    "    \n",
    "            self.handled=[True, True, True, True, False]\n",
    "            \n",
    "            self._mega_image_cache = None\n",
    "    \n",
    "            self._empty=self._get_empty().to(device)\n",
    "    \n",
    "            self._images = [self.get_a, self.get_b, self.get_c, self.get_d, self.get_z]\n",
    "    \n",
    "        def _get_empty(self):\n",
    "            #Instead of refactoring the code to take two images, I'll just nullify the others...\n",
    "            with torch.no_grad():\n",
    "                return torch.zeros(3,self.SIZE,self.SIZE)\n",
    "            \n",
    "        def _get_sub_image(self,index,cached=False):\n",
    "            #Use invalidation for big speed boost!\n",
    "            return self._primes[index]()\n",
    "    \n",
    "        def get_base(self):\n",
    "            return self._get_sub_image(0)\n",
    "    \n",
    "        def get_rotator(self):\n",
    "            return self._get_sub_image(1)\n",
    "            \n",
    "        def get_a(self):return simulate_overlay( self.get_base(),  self.get_rotator().rot90(k=0,dims=[1,2]) )\n",
    "        \n",
    "        def get_b(self):return simulate_overlay( self.get_base(),  self.get_rotator().rot90(k=1,dims=[1,2]) )\n",
    "            \n",
    "        def get_c(self):return simulate_overlay( self.get_base(),  self.get_rotator().rot90(k=2,dims=[1,2]) )\n",
    "            \n",
    "        def get_d(self):return simulate_overlay( self.get_base(),  self.get_rotator().rot90(k=3,dims=[1,2]) )\n",
    "    \n",
    "        def get_z(self):return self._empty\n",
    "    \n",
    "        def __getitem__(self,index):\n",
    "            return self._images[index]\n",
    "            \n",
    "        def __len__(self):\n",
    "            return len(self._images)\n",
    "    \n",
    "    \n",
    "    if TYPE=='HIDDEN':\n",
    "        learnable_images_bundle=IndependentLearnableImageBatch().to(device)\n",
    "    elif TYPE=='FLIPPY':\n",
    "        learnable_images_bundle=FlippyImageBatch().to(device)\n",
    "    elif TYPE=='ROTATOR':\n",
    "        learnable_images_bundle=RotatorImageBatch().to(device)\n",
    "    else:\n",
    "        assert False,'bad TYPE: '+str(TYPE)\n",
    "    \n",
    "    SIZE=learnable_images_bundle.SIZE\n",
    "    handled=learnable_images_bundle.handled\n",
    "    \n",
    "    \n",
    "    \n",
    "    # learnable_image_a=lambda: image_a()\n",
    "    # learnable_image_b=lambda: image_b()\n",
    "    # learnable_image_c=lambda: image_c()\n",
    "    # learnable_image_d=lambda: image_d()\n",
    "    # learnable_image_z=lambda: simulate_overlay(image_a(), image_b(), image_c(), image_d())\n",
    "    \n",
    "    # params=chain(\n",
    "    #     image_a.parameters(),\n",
    "    #     image_b.parameters(),\n",
    "    #     image_c.parameters(),\n",
    "    #     image_d.parameters(),\n",
    "    # )\n",
    "    \n",
    "    params = learnable_images_bundle.parameters()\n",
    "    optim=torch.optim.SGD(params,lr=dict(FOURIER=1e-4, RASTER=1)[PARAM])\n",
    "    \n",
    "    labels=[label_a, label_b, label_c, label_d, label_z]\n",
    "    learnable_images = [learnable_image_a,learnable_image_b,learnable_image_c,learnable_image_d,learnable_image_z] = list(learnable_images_bundle)\n",
    "    \n",
    "    #The weight coefficients for each prompt. For example, if we have [1,1,1,1,5], then the hidden prompt (prompt_z) will be prioritized\n",
    "    weights=[1,1,1,1,2]\n",
    "    \n",
    "    weights=rp.as_numpy_array(weights)\n",
    "    weights=weights/weights.sum()\n",
    "    weights=weights*len(weights)\n",
    "    \n",
    "    #For saving a timelapse\n",
    "    ims=[]\n",
    "    \n",
    "    def get_display_image():\n",
    "        return rp.tiled_images(\n",
    "            [\n",
    "                *[rp.as_numpy_image(image()) for image in learnable_images[:-1]],\n",
    "                rp.as_numpy_image(learnable_image_z()),\n",
    "            ],\n",
    "            length=len(learnable_images),\n",
    "            border_thickness=0,\n",
    "        )\n",
    "    \n",
    "    NUM_ITER=SDS_ITERS #We don't use SDS anymore\n",
    "    \n",
    "    weights=[1.5,1,1,1,1]\n",
    "    \n",
    "    \n",
    "    # NUM_ITER=10000\n",
    "    \n",
    "    #Set the minimum and maximum noise timesteps for the dream loss (aka score distillation loss)\n",
    "    s.max_step=MAX_STEP=990\n",
    "    s.min_step=MIN_STEP=10 \n",
    "    \n",
    "    display_eta=rp.eta(NUM_ITER, title='Status: ')\n",
    "    \n",
    "    DISPLAY_INTERVAL = 200\n",
    "    \n",
    "    print('Every %i iterations we display an image in the form [image_a, image_b, image_c, image_d, image_z] where'%DISPLAY_INTERVAL)\n",
    "    print('    image_z = image_a * image_b * image_c * image_d')\n",
    "    print()\n",
    "    print('Interrupt the kernel at any time to return the currently displayed image')\n",
    "    print('You can run this cell again to resume training later on')\n",
    "    print()\n",
    "    print('Please expect this to take hours to get good images (especially on the slower Colab GPU\\'s! The longer you wait the better they\\'ll be')\n",
    "    \n",
    "    try:\n",
    "        for iter_num in range(NUM_ITER):\n",
    "            display_eta(iter_num) #Print the remaining time\n",
    "    \n",
    "            preds=[]\n",
    "            for is_handled,label,learnable_image,weight in rp.random_batch(list(zip(handled,labels,learnable_images,weights)), batch_size=1):\n",
    "                if not is_handled:\n",
    "                    continue\n",
    "                pred=s.train_step(\n",
    "                    label.embedding,\n",
    "                    learnable_image()[None],\n",
    "    \n",
    "                    #PRESETS (uncomment one):\n",
    "                    noise_coef=.1*weight,guidance_scale=60,#10\n",
    "                    # noise_coef=0,image_coef=-.01,guidance_scale=50,\n",
    "                    # noise_coef=0,image_coef=-.005,guidance_scale=50,\n",
    "                    # noise_coef=.1,image_coef=-.010,guidance_scale=50,\n",
    "                    # noise_coef=.1,image_coef=-.005,guidance_scale=50,\n",
    "                    # noise_coef=.1*weight, image_coef=-.005*weight, guidance_scale=50,\n",
    "                )\n",
    "                preds+=list(pred)\n",
    "    \n",
    "            if not iter_num%DISPLAY_INTERVAL:\n",
    "                im = get_display_image()\n",
    "                ims.append(im)\n",
    "                with torch.no_grad():\n",
    "                    if iter_num and not iter_num%(DISPLAY_INTERVAL*50):\n",
    "                        #Wipe the slate every 50 displays so they don't get cut off\n",
    "                        from IPython.display import clear_output\n",
    "                        clear_output()\n",
    "        \n",
    "                    if not iter_num%DISPLAY_INTERVAL:\n",
    "                        rp.display_image(im)\n",
    "    \n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "    except KeyboardInterrupt:\n",
    "        print()\n",
    "        print('Interrupted early at iteration %i'%iter_num)\n",
    "        im = get_display_image()\n",
    "        ims.append(im)\n",
    "        rp.display_image(im)\n",
    "    \n",
    "    print('Image A')\n",
    "    rp.display_image(rp.as_numpy_image(learnable_image_a()))\n",
    "    \n",
    "    print('Image B')\n",
    "    rp.display_image(rp.as_numpy_image(learnable_image_b()))\n",
    "    \n",
    "    print('Image C')\n",
    "    rp.display_image(rp.as_numpy_image(learnable_image_c()))\n",
    "    \n",
    "    print('Image D')\n",
    "    rp.display_image(rp.as_numpy_image(learnable_image_d()))\n",
    "    \n",
    "    print('Image Z')\n",
    "    rp.display_image(rp.as_numpy_image(learnable_image_z()))\n",
    "    \n",
    "    # def save_run(name):\n",
    "    #     folder=\"untracked/hidden_character_runs/%s\"%name\n",
    "    #     if rp.path_exists(folder):\n",
    "    #         folder+='_%i'%time.time()\n",
    "    #     rp.make_directory(folder)\n",
    "    #     ims_names=['ims_%04i.png'%i for i in range(len(ims))]\n",
    "    #     print()\n",
    "    #     rp.save_video_mp4(ims,folder+'.mp4',video_bitrate='high')\n",
    "    #     with rp.SetCurrentDirectoryTemporarily(folder):\n",
    "    #         rp.save_images(ims,ims_names,show_progress=True)\n",
    "    #         pass\n",
    "    #     print('Saved timelapse to folder:',repr(folder))\n",
    "        \n",
    "    # save_run(title) #You can give it a good custom name if you want!\n",
    "    \n",
    "    \n",
    "    \n",
    "    logger_images=[]\n",
    "    logger_timestamps=[]\n",
    "    logger_targets=[]\n",
    "    logger_losses=[]\n",
    "    \n",
    "    GRAYSCALE=True\n",
    "    GRAYSCALE=False\n",
    "    \n",
    "    MSSSIM_MULT=dict(RASTER=1,FOURIER=1)[PARAM] * .5\n",
    "    try:\n",
    "        def global_set(**names_vals):\n",
    "            def out():\n",
    "                for name,val in names_vals.items():\n",
    "                    rp.fansi_print(\"SETTING \"+name+\" TO \"+str(val), 'green','bold')\n",
    "                    globals()[name]=val\n",
    "            return out\n",
    "        \n",
    "        import icecream\n",
    "            \n",
    "        if not HEADLESS:\n",
    "    \n",
    "    \n",
    "            # FREEZE=[0,0,0,0,0]\n",
    "            # WEIGHTS_LIST=[1,1,1,1,1.5] #If one of the images looks sus, add more weight!\n",
    "            # WEIGHTS_LIST=[1,1,1,1,2] #If one of the images looks sus, add more weight!\n",
    "    \n",
    "            WEIGHT_ON_WORST=False #Boost the worst?\n",
    "            \n",
    "            # WEIGHTS_LIST=[1,1,1,1,3] #If one of the images looks sus, add more weight!\n",
    "            # sss=[1]+rp.shuffled(rp.resize_list([.9,.7,.6,.5,.3,.2],100));GUIDANCE=7.5;STEPS=2000;SMOOTH_PROB=.0;NUM_IM2IM_STEPS=50  ; MSSSIM_COEF = 0 ; MSE_COEF = 1 ; WEIGHTS_LIST=[1,1,1,1,2]#COMPLETE - fast'n sloppy\n",
    "            # sss=rp.shuffled(rp.resize_list([.7],100));GUIDANCE=7.5;STEPS=2000;SMOOTH_PROB=0;NUM_IM2IM_STEPS=50  ; MSSSIM_COEF = .2 ; MSE_COEF = 1 ; WEIGHTS_LIST=[1,1,1,1,2]\n",
    "            # sss=rp.shuffled(rp.resize_list([.5],100));GUIDANCE=7.5;STEPS=2000;SMOOTH_PROB=0;NUM_IM2IM_STEPS=50  ; MSSSIM_COEF = .2 ; MSE_COEF = 1; WEIGHTS_LIST=[1,1,1,1,2]\n",
    "            # sss=rp.shuffled(rp.resize_list([.5],100));GUIDANCE=7.5;STEPS=20000;SMOOTH_PROB=0;NUM_IM2IM_STEPS=50  ; MSSSIM_COEF = .2 ; MSE_COEF = 1; WEIGHTS_LIST=[1,1,1,1,2]\n",
    "            \n",
    "            \n",
    "            ZI_OVERRIDE=None\n",
    "            # ZI_OVERRIDE=rp.load_image(\"https://m.media-amazon.com/images/I/51nHtpT5hEL._AC_UF894,1000_QL80_.jpg\",use_cache=True) ; WEIGHTS_LIST=[1,1,1,1,.5]\n",
    "            # ZI_OVERRIDE=rp.inverted_image(rp.load_image(\"https://i.imgur.com/BlnAQxm.png\",use_cache=True)) ; WEIGHTS_LIST=[1,1,1,1,.5] #rig poem\n",
    "            # ZI_OVERRIDE=rp.load_image(\"https://i.imgur.com/F006VHD.png\",use_cache=True) ; #WEIGHTS_LIST=[1,1,1,1,.5]\n",
    "            # ZI_OVERRIDE=rp.inverted_image(rp.load_image(\"https://m.media-amazon.com/images/I/612+XnLD1RL._AC_UF894,1000_QL80_.jpg\",use_cache=True)) ; WEIGHTS_LIST=[1,1,1,1,1/2] #Pentagram\n",
    "            # ZI_OVERRIDE=rp.load_image(\"https://cdn2.vectorstock.com/i/1000x1000/97/86/colorful-rainbow-swirl-vector-1549786.jpg\",use_cache=True) ; WEIGHTS_LIST=[1,1,1,1,1/2] #Rainbow Swirl\n",
    "            # ZI_OVERRIDE=rp.load_image(\"https://upload.wikimedia.org/wikipedia/en/e/ed/Nyan_cat_250px_frame.PNG\",use_cache=True) ; WEIGHTS_LIST=[1,1,1.5,2,2] #Nyan Cat\n",
    "            \n",
    "            # ZI_OVERRIDE=rp.load_image(\"https://i.imgur.com/IrkQ4f3.jpeg\",use_cache=True) ; WEIGHTS_LIST=[1,1,1,1,.5]\n",
    "            \n",
    "            START_HERE=hash(object())\n",
    "            \n",
    "            sss=[\n",
    "                START_HERE, #A bookmark\n",
    "                dict(\n",
    "                    GUIDANCE=20,\n",
    "                    # WEIGHTS_LIST=[1,1,1,1,1] if ZI_OVERRIDE is None else [1,1,1,1,1],\n",
    "                    WEIGHTS_LIST=[1,1,1,1,4],\n",
    "                    STEPS=1000 *dict(RASTER=1,FOURIER=1)[PARAM],\n",
    "                    SMOOTH_PROB=0,\n",
    "                    FREEZE=[0,0,0,0,0],\n",
    "                    MSE_COEF=1,\n",
    "                    MSSSIM_COEF=.4 * (MSSSIM_MULT), #SPEEDUP\n",
    "                    # MSSSIM_COEF=0, #SPEEDUP\n",
    "                    NUM_IM2IM_STEPS=20, #SPEEDUP\n",
    "                    AUTO_WEIGHT=True,\n",
    "                ),\n",
    "                # global_set(WEIGHTS_LIST=[1,1,1,1,1]),\n",
    "                # global_set(MSSSIM_COEF=0),\n",
    "                1,.9,.85,#.5,.3],#,1,.7,.5,.3],\n",
    "                dict(FREEZE=[0,0,0,0,1],\n",
    "                     WEIGHTS_LIST=[1,1,1,1,3], \n",
    "                     MSSSIM_COEF=1 *  (MSSSIM_MULT),\n",
    "                     AUTO_WEIGHT=False),\n",
    "                .85,.8,.75,\n",
    "                \n",
    "                # global_set(WEIGHTS_LIST=[1,1,1,1,2]),\n",
    "                \n",
    "                dict(AUTO_WEIGHT=False),\n",
    "                # global_set(GUIDANCE=32),\n",
    "                # global_set(STEPS=2000 if BIG else 5000),\n",
    "                # global_set(GUIDANCE=4),\n",
    "                # WEIGHTS_LIST=[1,1,1,1,2],\n",
    "                dict(\n",
    "                    STEPS=2000,\n",
    "                    WEIGHTS_LIST=[1,1,1,1,1],\n",
    "                    # WEIGHT_ON_WORST=True,\n",
    "                ),\n",
    "                dict(MSSSIM_COEF=1 *  (MSSSIM_MULT)),\n",
    "                dict(GUIDANCE=30),\n",
    "                *[.7,.5],\n",
    "    \n",
    "    \n",
    "                # dict(\n",
    "                    # STEPS=2000,\n",
    "                    # WEIGHTS_LIST=[1,1,1,1,.5],\n",
    "                    # WEIGHT_ON_WORST=True,\n",
    "                # ),\n",
    "    \n",
    "                \n",
    "                *[.7,.5]*1,\n",
    "    \n",
    "                # dict(\n",
    "                #     WEIGHTS_LIST=[1,1,1,1,1],\n",
    "                #     FREEZE=[0,0,0,0,0],\n",
    "                # ),\n",
    "    \n",
    "                *[.7,.5]*3,\n",
    "    \n",
    "                \n",
    "                *[.7,.5]*2,\n",
    "                *[.5]*2,\n",
    "                dict(STEPS=20000),\n",
    "                *[.5]*1,\n",
    "            ]\n",
    "\n",
    "        sss=sss[:int(len(sss)*.5)] #FOR AUTOMATION ONLY\n",
    "        \n",
    "        \n",
    "        if START_HERE in sss:\n",
    "            SSS_BOOKMARK_INDEX=sss.index(START_HERE)\n",
    "            rp.fansi_print(\"STARTING FROM BOOKMARK\",'yellow','bold')\n",
    "            sss=sss[SSS_BOOKMARK_INDEX+1:]\n",
    "        \n",
    "        \n",
    "        #No longer used\n",
    "        # sss=rp.shuffled(rp.resize_list([.3],100));GUIDANCE=7.5;STEPS=1500;SMOOTH_PROB=0;NUM_IM2IM_STEPS=50  ; MSSSIM_COEF = .2 ; MSE_COEF = 1; WEIGHTS_LIST=[1,1,1,1,2]\n",
    "        # sss=rp.shuffled(rp.resize_list([.4,.3,.2],100));GUIDANCE=7.5;STEPS=3000;SMOOTH_PROB=.5;NUM_IM2IM_STEPS=50 ; MSSSIM_COEF = 0 ; MSE_COEF = 1 ; WEIGHTS_LIST=[1,1,1,1,2]\n",
    "        # sss=rp.shuffled(rp.resize_list([.3],100));GUIDANCE=7.5;STEPS=20000;SMOOTH_PROB=0;NUM_IM2IM_STEPS=50  ; MSSSIM_COEF = .2 ; MSE_COEF = 1; WEIGHTS_LIST=[1,1,1,1,2]\n",
    "        # sss=rp.shuffled(rp.resize_list([.8],100));GUIDANCE=7.5;STEPS=2000;SMOOTH_PROB=0;NUM_IM2IM_STEPS=50  ; MSSSIM_COEF = .2 ; MSE_COEF = 1 ; WEIGHTS_LIST=[1,1,1,1,2]\n",
    "        \n",
    "        \n",
    "        # WEIGHTS_LIST=[2,1,1,1,1]\n",
    "        skips=[False]*len(learnable_images)\n",
    "        for SSS_INDEX, STRENGTH in enumerate(sss):\n",
    "        \n",
    "            if isinstance(STRENGTH,dict):\n",
    "                global_set(**STRENGTH)()\n",
    "                continue\n",
    "            else:\n",
    "                rp.fansi_print('IM2IM STRENGTH '+str(STRENGTH),'yellow','bold')\n",
    "            \n",
    "            import torch.nn.functional as F\n",
    "        \n",
    "            rp.pretty_print(rp.gather_vars(\n",
    "                # SSS_INDEX+SSS_BOOKMARK_INDEX,\n",
    "                'SSS_INDEX',\n",
    "                'SSS_BOOKMARK_INDEX',\n",
    "                'STRENGTH',\n",
    "                'GUIDANCE',\n",
    "                'STEPS',\n",
    "                'SMOOTH_PROB',\n",
    "                'NUM_IM2IM_STEPS',\n",
    "                'MSSSIM_COEF',\n",
    "                'MSE_COEF',\n",
    "                'WEIGHTS_LIST',\n",
    "                'USE_SDXL',\n",
    "                skip_missing=True,\n",
    "            ))\n",
    "            \n",
    "            \n",
    "        \n",
    "            if logger_images:\n",
    "                for x in rp.resize_list(logger_images[::-1],10):\n",
    "                    rp.display_image(x)\n",
    "            #               GUIDANCE=32 ;  TIMESTEPS=range(100, 75, -1) ;  EMA_ALPHA=.2 ;  ORIG_ALPHA=.05 ; NEG='blurry unfocused low quality bokeh, depth of field' ;#Medium Light\n",
    "            #               GUIDANCE=32 ;  TIMESTEPS=range(100, 75, -1) ;  EMA_ALPHA=.2 ;  ORIG_ALPHA=.015 ; NEG='blurry unfocused low quality bokeh, depth of field' ;#Medium Light\n",
    "            # GUIDANCE=32 ;  TIMESTEPS=range(300, 75, -5) ;  EMA_ALPHA=.2 ;  ORIG_ALPHA=.055 ; NEG='blurry unfocused low quality bokeh, depth of field' ;#Medium Harsh\n",
    "            # GUIDANCE=32 ;  TIMESTEPS=range(300, 75, -5) ;  EMA_ALPHA=.2 ;  ORIG_ALPHA=.025 ; NEG='blurry unfocused low quality bokeh, depth of field' ;#Medium Harsh\n",
    "            # GUIDANCE=16 ;  TIMESTEPS=range(300, 200, -1) ;  EMA_ALPHA=.2 ;  ORIG_ALPHA=.025 ; NEG='blurry unfocused low quality bokeh, depth of field' ;#Medium Harsh\n",
    "            # GUIDANCE=32 ;  TIMESTEPS=range(500, 10, -10) ;  EMA_ALPHA=.2 ;  ORIG_ALPHA=.01 ; NEG='blurry unfocused low quality bokeh, depth of field' ; #Aggressive\n",
    "            # GUIDANCE=4 ;  TIMESTEPS=range(999, 500, -10) ;  EMA_ALPHA=1 ;  ORIG_ALPHA=0 ; NEG='oversaturated, blurry unfocused low quality bokeh, depth of field, unrealistic, abstract, deep fried' ; #Complete\n",
    "            # GUIDANCE=20 ;  TIMESTEPS=range(999, 10, -2) ;  EMA_ALPHA=.05 ;  ORIG_ALPHA=0 ; NEG='' ; #Complete\n",
    "            # GUIDANCE=7 ;  TIMESTEPS=range(999, 10, -2) ;  EMA_ALPHA=.1 ;  ORIG_ALPHA=0 ; NEG='' ; #Complete\n",
    "            \n",
    "            # COMPLETE=True#If this is set to True, generate the images totally from scratch using the default method\n",
    "            # COMPLETE=False\n",
    "            \n",
    "            #Show a timelapse of each diffusion process. Can take a while to load into the notebook.\n",
    "            # SHOW_ANIMS=True\n",
    "            # SHOW_ANIMS=False \n",
    "            \n",
    "            # @rp.monkey_patch(sd.StableDiffusion)\n",
    "            # def redenoise_latent(self,                   text_embeddings:torch.Tensor,\n",
    "            #                    latent:torch.Tensor,\n",
    "            #                    guidance_scale:float=GUIDANCE,\n",
    "            #                    t:int=None,):\n",
    "                    \n",
    "            #         if t is None:\n",
    "            #             t = torch.randint(self.min_step, self.max_step + 1, [1], dtype=torch.long, device=self.device)\n",
    "            \n",
    "            #         assert 0<=t<self.num_train_timesteps, 'invalid timestep t=%i'%t\n",
    "            \n",
    "            #         latents=latent[None]\n",
    "            \n",
    "                    \n",
    "            #         # predict the noise residual with unet, NO grad!\n",
    "            #         with torch.no_grad():\n",
    "            #             # add noise\n",
    "            #             noise = torch.randn_like(latents)\n",
    "            #             #This is the only place we use the scheduler...the add_noise function. What's more...it's totally generic! The scheduler doesn't impact the implementation of train_step...\n",
    "            #             if t==999:\n",
    "            #                 latents_noisy=noise+0 #Eh sometimes I want to have complete noise\n",
    "            #             else:\n",
    "            #                 latents_noisy = self.add_noise(latents, noise, t) #The add_noise function is identical for PNDM, DDIM, and DDPM schedulers in the diffusers library\n",
    "            #             #TODO: Expand this add_noise function, and put it in this class. That way we don't need the scheduler...and we can also add an inverse function, which is what I need for previews...that subtracts noise...\n",
    "            #             #Also, create a dream-loss-based image gen example notebook...\n",
    "            \n",
    "            #             # pred noise\n",
    "            #             latent_model_input = torch.cat([latents_noisy] * 2)\n",
    "            #             noise_pred = self.predict_noise(latent_model_input, text_embeddings, t)\n",
    "            \n",
    "                                    \n",
    "            #             noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
    "            #             noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
    "                        \n",
    "            #             latent_pred = self.remove_noise(latents_noisy, noise_pred, t)\n",
    "            #             # rp.ic(latent_pred.shape)\n",
    "            #             output = latent_pred[0]\n",
    "                        \n",
    "            #             # latent_pred = self.decode_latents(latent_pred)[0]\n",
    "            \n",
    "            #         return latent_pred[0]\n",
    "            \n",
    "            \n",
    "                \n",
    "            # def denoise_l(latent,label,T):\n",
    "            #     return s.redenoise_latent(latent=latent,\n",
    "            #                               text_embeddings=label.embedding,\n",
    "            #                               t=torch.tensor(T, dtype=torch.int)\n",
    "            #                              )\n",
    "                \n",
    "            # def get_ii_seqo(w=learnable_image_z, lw=label_z):\n",
    "            #     seqo=[]\n",
    "                \n",
    "            #     if COMPLETE:\n",
    "            #         out=lw.get_sample_image()\n",
    "            #         rp.display_image(out)\n",
    "            #         return out,[out]\n",
    "                \n",
    "            #     with torch.no_grad():\n",
    "            #         # w,lw=learnable_image_x,label_x\n",
    "            #         # w,lw=learnable_image_y,label_y\n",
    "            #         # w,lw=learnable_image_z,label_z\n",
    "            \n",
    "            #         lw=NegativeLabel(lw.name,NEG)\n",
    "            \n",
    "            #         w=w()\n",
    "            #         i=w\n",
    "            #         i = F.interpolate(i[None], (512, 512), mode='bilinear', align_corners=False)[0]\n",
    "            #         l=s.encode_img(i)\n",
    "            #         ol=l\n",
    "            \n",
    "            #         rp.display_image(rp.as_numpy_image(i))\n",
    "            \n",
    "            #         # for T in [10]*100:\n",
    "            #         # for T in [100,100,100,100,100]*10:\n",
    "            #         # for T in [100,100,100,100,100]:\n",
    "            #         rp.tic()\n",
    "            #         # for T in list(range(999, 0, -10)):\n",
    "            #         # for T in list(range(500, 0, -10)):\n",
    "            #         # for T in list(range(999, 0, -50)):\n",
    "            #         # for T in list(range(100, 0, -1)):\n",
    "            #         did_999=False\n",
    "            #         for T in list(TIMESTEPS):\n",
    "            #             if T==999:\n",
    "            #                 if did_999: continue\n",
    "            #                 did_999=True\n",
    "                            \n",
    "            #             if T!=999:\n",
    "            #                 T=rp.random_element(set(TIMESTEPS)-{999})\n",
    "            #             # torch.manual_seed(298)\n",
    "            \n",
    "            #             dl=denoise_l(l, lw, T)\n",
    "            #             # l=rp.blend(l,dl,1)#Stick to the previous, EMA, make it smooth! Less variance\n",
    "            #             # l=rp.blend(l,dl,.2)#Stick to the previous, EMA, make it smooth! Less variance\n",
    "            #             # l=rp.blend(l,dl,.01)#Stick to the previous, EMA, make it smooth! Less variance\n",
    "            #             if T!=999:\n",
    "            #                 l=rp.blend(l,dl,EMA_ALPHA)#Stick to the previous, EMA, make it smooth! Less variance\n",
    "            \n",
    "            #                 # l=rp.blend(l,ol,.05)#Stick to the original\n",
    "            #                 l=rp.blend(l,ol,ORIG_ALPHA)#Stick to the original\n",
    "            #             else:\n",
    "            #                 l=dl\n",
    "            #                 # l=dl\n",
    "            \n",
    "            #             from IPython.display import clear_output\n",
    "            #             # clear_output()\n",
    "            \n",
    "            #             ii=rp.as_numpy_image(s.decode_latent(l))\n",
    "            #             print(T)\n",
    "            #             seqo.append(rp.cv_resize_image(ii,.5))\n",
    "            #             if rp.toc()>10:\n",
    "            #                 rp.display_image(ii)\n",
    "            #                 rp.tic()\n",
    "            #         rp.display_image(ii)\n",
    "            #         return ii,seqo\n",
    "            \n",
    "            import rp\n",
    "            import requests\n",
    "            import torch\n",
    "            from PIL import Image\n",
    "            from io import BytesIO\n",
    "            \n",
    "            from diffusers import StableDiffusionImg2ImgPipeline,StableDiffusionXLImg2ImgPipeline\n",
    "        \n",
    "            if USE_SDXL:\n",
    "                if not 'im2im_pipe' in dir():\n",
    "                    im2im_model_id_or_path = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "                    im2im_pipe = StableDiffusionXLImg2ImgPipeline.from_pretrained(im2im_model_id_or_path, torch_dtype=torch.float16,                requires_safety_checker=False,\n",
    "                                safety_checker=None,)\n",
    "                    im2im_pipe = im2im_pipe.to(device)\n",
    "                    im2im_size=1024\n",
    "            else:\n",
    "                if not 'im2im_pipe' in dir():\n",
    "                    im2im_model_id_or_path = \"runwayml/stable-diffusion-v1-5\"\n",
    "                    im2im_pipe = StableDiffusionImg2ImgPipeline.from_pretrained(im2im_model_id_or_path, torch_dtype=torch.float16,                requires_safety_checker=False,\n",
    "                                safety_checker=None,)\n",
    "                    im2im_pipe = im2im_pipe.to(device)\n",
    "                    im2im_size=512\n",
    "        \n",
    "            def im2im(image, prompt=\"\", strength=STRENGTH, guidance_scale=GUIDANCE):\n",
    "                image=rp.as_pil_image(rp.as_rgb_image(rp.as_float_image(rp.cv_resize_image(image,(im2im_size,im2im_size)))))\n",
    "                return im2im_pipe(prompt=prompt, image=image, strength=strength, num_inference_steps=NUM_IM2IM_STEPS,guidance_scale=guidance_scale).images[0]\n",
    "        \n",
    "            if not rp.random_chance(SMOOTH_PROB):\n",
    "                #Don't always do this?\n",
    "                def get_ii_seqo(learnable_image, label):\n",
    "                    i = learnable_image()\n",
    "                    i = F.interpolate(i[None], (512, 512), mode='bilinear', align_corners=False)[0]\n",
    "                    i = rp.as_numpy_image(i)\n",
    "                    o = im2im(i, prompt=label.name)\n",
    "                    return o,[i,o]\n",
    "        \n",
    "            SHOW_ANIMS=True\n",
    "            \n",
    "            if not FREEZE[0]:AI,seqo=get_ii_seqo(learnable_image_a,label_a)\n",
    "            if SHOW_ANIMS and handled[0]:rp.display_image_slideshow(seqo)\n",
    "            \n",
    "            if not FREEZE[1]:BI,seqo=get_ii_seqo(learnable_image_b,label_b)\n",
    "            if SHOW_ANIMS and handled[0]:rp.display_image_slideshow(seqo)\n",
    "            \n",
    "            if not FREEZE[2]:CI,seqo=get_ii_seqo(learnable_image_c,label_c)\n",
    "            if SHOW_ANIMS and handled[0]:rp.display_image_slideshow(seqo)\n",
    "            \n",
    "            if not FREEZE[3]:DI,seqo=get_ii_seqo(learnable_image_d,label_d)\n",
    "            if SHOW_ANIMS and handled[0]:rp.display_image_slideshow(seqo)\n",
    "            \n",
    "            if not FREEZE[4]:ZI,seqo=get_ii_seqo(learnable_image_z,label_z)\n",
    "            if ZI_OVERRIDE is not None  and handled[0]:\n",
    "                ZI=rp.cv_resize_image(ZI_OVERRIDE,rp.get_image_dimensions(ZI))\n",
    "                ZI=rp.blend_images(ZI,.5,.1) #Decrease contrast\n",
    "                ZI=rp.cv_gauss_blur(ZI,20) #Don't make gradient too sharp\n",
    "                ZI=rp.as_pil_image(rp.as_float_image(rp.as_rgb_image(ZI)))\n",
    "            if SHOW_ANIMS:rp.display_image_slideshow(seqo)\n",
    "            \n",
    "            #################################\n",
    "    \n",
    "            if GRAYSCALE:\n",
    "                [AI,BI,CI,DI,ZI]=map(lambda x:rp.as_pil_image(rp.as_rgb_image(rp.as_grayscale_image(x))),[AI,BI,CI,DI,ZI])\n",
    "            \n",
    "            rp.display_image(rp.tiled_images([AI,BI,CI,DI,ZI]))\n",
    "            \n",
    "            \n",
    "            ##########\n",
    "            \n",
    "            #######################\n",
    "            targets=[AI,BI,CI,DI,ZI]\n",
    "            down_images=rp.as_torch_images(rp.as_numpy_array([rp.cv_resize_image(rp.as_numpy_image(x),(SIZE,SIZE)) for x in targets])).to(s.device)\n",
    "            \n",
    "            ###########\n",
    "            \n",
    "            ######################\n",
    "            \n",
    "            shlump=[]\n",
    "            \n",
    "            ############\n",
    "            \n",
    "            #####################\n",
    "            \n",
    "            from source.msssim import msssim\n",
    "            \n",
    "            # WEIGHTS=[1,2,1.5,2] #If one of the images looks sus, add more weight!\n",
    "            # WEIGHTS=[1,1,1,1,5] #If one of the images looks sus, add more weight!\n",
    "            # WEIGHTS=[1,1,1,1,2] #If one of the images looks sus, add more weight!\n",
    "            # WEIGHTS=[1,1,1,1,1.5] #If one of the images looks sus, add more weight!\n",
    "            # WEIGHTS=[0,0,0,0,1] #Fix Z and only go to it\n",
    "            # WEIGHTS=[1,1,1,.3,1] #Fix Z and only go to it\n",
    "            # WEIGHTS=[1,1,1,.3,5] #Fix Z and only go to it\n",
    "            # WEIGHTS=[1,1,1,1,10] #Fix Z and only go to it\n",
    "            # WEIGHTS=[1,1,1,1,1] #Fix Z and only go to it\n",
    "            WEIGHTS=WEIGHTS_LIST\n",
    "            WEIGHTS=rp.as_numpy_array(WEIGHTS)\n",
    "            WEIGHTS=WEIGHTS/WEIGHTS.sum()\n",
    "            \n",
    "            # MSSSIM_COEF = 0 ; MSE_COEF = 1\n",
    "            # MSSSIM_COEF = .2 ; MSE_COEF = 1        # ORIGINAL MIKU PUBLISHED\n",
    "            # MSSSIM_COEF = .5 ; MSE_COEF = 1\n",
    "            # MSSSIM_COEF = 1 ; MSE_COEF = 1\n",
    "            \n",
    "            for _ in range(STEPS):\n",
    "                if not _%(500*2):\n",
    "                    with torch.no_grad():\n",
    "                        OLD_RANDOM_SHIFT=RANDOM_SHIFT\n",
    "                        try:\n",
    "                            RANDOM_SHIFT=False\n",
    "                            shlumper=rp.tiled_images(\n",
    "                                [\n",
    "                                    rp.as_numpy_image(learnable_image_a()),\n",
    "                                    rp.as_numpy_image(learnable_image_b()),\n",
    "                                    rp.as_numpy_image(learnable_image_c()),\n",
    "                                    rp.as_numpy_image(learnable_image_d()),\n",
    "                                    rp.as_numpy_image(learnable_image_z()),\n",
    "                                ]+\n",
    "                                (\n",
    "                                    [\n",
    "                                        rp.as_numpy_image(learnable_images_bundle.get_base()),\n",
    "                                        rp.as_numpy_image(learnable_images_bundle.get_rotator()),\n",
    "                                    ] \n",
    "                                    if TYPE=='ROTATOR' else []\n",
    "                                )\n",
    "                                ,\n",
    "                                border_thickness=0,\n",
    "                                length=5\n",
    "                            )\n",
    "                        finally:\n",
    "                            RANDOM_SHIFT=OLD_RANDOM_SHIFT\n",
    "                    rp.display_image(shlumper)\n",
    "        \n",
    "                losses = [-10000]*len(learnable_images)\n",
    "                limage=learnable_images\n",
    "                index=_%len(limage)\n",
    "        \n",
    "                for lindex,limage in enumerate(learnable_images):\n",
    "                    if not handled[lindex]:\n",
    "                        continue\n",
    "                    skip = skips[lindex]\n",
    "                \n",
    "                    limage=learnable_images[lindex]\n",
    "                    limage=limage()\n",
    "                    dimage=down_images[lindex]\n",
    "                    loss=0\n",
    "                \n",
    "                    with rp.ConditionalContext(skip, torch.no_grad):\n",
    "                        if MSE_COEF   : mse_loss   =((limage-dimage)**2).mean()       * MSE_COEF    ; loss=loss+mse_loss\n",
    "                        if MSSSIM_COEF: msssim_loss=msssim(limage[None],dimage[None]) * MSSSIM_COEF ; loss=loss-msssim_loss\n",
    "        \n",
    "                    total_loss=loss*4*WEIGHTS[lindex]\n",
    "                        \n",
    "                    total_loss=total_loss*10000\n",
    "        \n",
    "                    if not skip:\n",
    "                        total_loss.backward()\n",
    "                        optim.step()\n",
    "                        optim.zero_grad()\n",
    "        \n",
    "                    losses[lindex]=(float(mse_loss))\n",
    "                    # losses[lindex]=(float(total_loss))\n",
    "    \n",
    "                if WEIGHT_ON_WORST:\n",
    "                    #Optimize all 4\n",
    "                    WEIGHTS=WEIGHTS_LIST.copy()\n",
    "                    WEIGHTS[rp.max_valued_index(losses)]*=4\n",
    "                    WEIGHTS=rp.as_numpy_array(WEIGHTS)\n",
    "                    \n",
    "                FAST_FOCUS=not _%3 and AUTO_WEIGHT\n",
    "                # FAST_FOCUS=True\n",
    "                if FAST_FOCUS:\n",
    "                    #ONLY Optimize 1! Focus on 1, it's faster. Fast focus.\n",
    "                    skips=[True]*len(learnable_images)\n",
    "                    skips[rp.max_valued_index(losses)]=False\n",
    "                else:\n",
    "                    skips=[0,0,0,0,0]\n",
    "                    \n",
    "                if not _%21:\n",
    "                    logger_losses.append(rp.gather_vars('SSS_INDEX losses _'))\n",
    "                    print('LOSSES:', ' '.join(('%.5f'%loss).ljust(10) for loss in losses),end=' ')\n",
    "                    # print(\"WEIGHTS:\",WEIGHTS)\n",
    "                    print(\"    SKIPS:\",''.join('·' if x else 'X' for x in skips))\n",
    "                    WEIGHTS=WEIGHTS/WEIGHTS.sum()\n",
    "        \n",
    "        \n",
    "        \n",
    "                # losses = []\n",
    "                # for \n",
    "                # limage=[\n",
    "                #     learnable_image_a,\n",
    "                #     learnable_image_b,\n",
    "                #     learnable_image_c,\n",
    "                #     learnable_image_d,\n",
    "                #     learnable_image_z,\n",
    "                # ]\n",
    "                # index=_%len(limage)\n",
    "                \n",
    "                # if not WEIGHTS[index]:continue\n",
    "                \n",
    "                # limage=limage[index]\n",
    "                # limage=limage()\n",
    "                # dimage=down_images[index]\n",
    "                # loss=0\n",
    "            \n",
    "            \n",
    "                # if MSE_COEF   : loss=loss+  ((limage-dimage)**2).mean()       * MSE_COEF\n",
    "                # if MSSSIM_COEF: loss=loss-  msssim(limage[None],dimage[None]) * MSSSIM_COEF\n",
    "            \n",
    "                # total_loss=loss*4*WEIGHTS[index]\n",
    "                    \n",
    "                # total_loss=total_loss*10000\n",
    "                    \n",
    "                # total_loss.backward()\n",
    "                # optim.step()\n",
    "                # optim.zero_grad()\n",
    "                \n",
    "                # if not _%51:\n",
    "                #     print(total_loss)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "            logger_images.append(shlumper)\n",
    "            logger_targets.append(rp.horizontally_concatenated_images(rp.as_numpy_images(targets)))\n",
    "            logger_timestamps.append(rp.gtoc())\n",
    "            \n",
    "            from IPython.display import clear_output\n",
    "            clear_output()\n",
    "            print(STRENGTH)\n",
    "    except KeyboardInterrupt:\n",
    "        rp.fansi_print(\"INTERRUPTED\",'cyan','bold')\n",
    "    \n",
    "    # \n",
    "    \n",
    "    \n",
    "    \n",
    "    rp.display_image(logger_images[-1])\n",
    "    \n",
    "    len(logger_images)\n",
    "    \n",
    "    print(len(logger_images))\n",
    "    rp.display_image_slideshow(logger_images)\n",
    "    \n",
    "    with rp.SetCurrentDirectoryTemporarily(rp.make_directory(SAVE_DIR)):\n",
    "        name=rp.get_unique_copy_path(SAVE_TITLE)\n",
    "        with rp.SetCurrentDirectoryTemporarily(rp.make_directory(name)):\n",
    "            rp.save_images(logger_images, [name+'___logger_%04i.png'%i for i in range(len(logger_images))],show_progress=True)\n",
    "            rp.save_images(logger_targets, [name+'___targets_%04i.png'%i for i in range(len(logger_targets))],show_progress=True)\n",
    "            rp.save_images(ims, [name+'___sds_%04i.png'%i for i in range(len(ims))],show_progress=True)\n",
    "            rp.string_to_text_file('prompts.txt',rp.line_join([prompt_a,prompt_b,prompt_c,prompt_d,prompt_z]))\n",
    "            \n",
    "            metadata=rp.gather_vars('prompt_a prompt_b prompt_c prompt_d prompt_z logger_timestamps',\n",
    "                                    'BIG',\n",
    "                                    '',\n",
    "                                    'start_time',\n",
    "                                    'USE_SDXL',\n",
    "                                    '',\n",
    "                                    'SAVE_DIR',\n",
    "                                    'SAVE_TITLE',\n",
    "                                    'logger_losses',\n",
    "                                    '',\n",
    "                                    'SDS_ITERS',\n",
    "                                    '',\n",
    "                                    # 'gpu',\n",
    "                                    '',\n",
    "                                    'model_name',\n",
    "                                    '',\n",
    "                                    'HEADLESS',\n",
    "                                    '',\n",
    "                                    'title',\n",
    "                                    'negative_prompt',\n",
    "                                    'CLEAN_MODE',\n",
    "                                    'SIZE',\n",
    "                                    '',\n",
    "                                    'MAX_STEP',\n",
    "                                    'MIN_STEP',\n",
    "                                    '',\n",
    "                                    'DISPLAY_INTERVAL',\n",
    "                                    '',\n",
    "                                    'name',\n",
    "                                    '',\n",
    "                                    'SEED',\n",
    "                                    '',\n",
    "                                    'SSS_INDEX',\n",
    "                                    'SSS_BOOKMARK_INDEX',\n",
    "                                    'STRENGTH',\n",
    "                                    'GUIDANCE',\n",
    "                                    'STEPS',\n",
    "                                    'SMOOTH_PROB',\n",
    "                                    'NUM_IM2IM_STEPS',\n",
    "                                    'MSSSIM_COEF',\n",
    "                                    'MSE_COEF',\n",
    "                                    'WEIGHTS_LIST',\n",
    "                                    'sss',\n",
    "                                    'prompt_structure',\n",
    "                                    'possible_subjects',\n",
    "                                    'subjects',\n",
    "                                    'prompts_abcdz',\n",
    "                                    'method_name',\n",
    "                                    'TYPE',\n",
    "                                   skip_missing=True)\n",
    "            rp.save_json(metadata,'metadata.json',pretty=True)\n",
    "            \n",
    "        print(\"Done!\")\n",
    "    \n",
    "    print(name)\n",
    "    def line_graph_via_bokeh(values, *,\n",
    "                             xlabel: str = None,\n",
    "                             ylabel: str = None,\n",
    "                             title: str = None,\n",
    "                             logx: bool = False,\n",
    "                             logy: bool = False,\n",
    "                             height: float = 400,\n",
    "                             width: float = None):\n",
    "        \"\"\"\n",
    "        Display an interactive line graph using the Bokeh library in an IPython notebook.\n",
    "        Supports multiple formats for 'values' including lists and dictionaries.\n",
    "        Can interpret lists of shape (2, ...) or (..., 2) as x and y coordinates. Automatically assigns colors to multiple graphs.\n",
    "    \n",
    "        :param values: A list or dictionary of values. Interprets (2, ...) or (..., 2) shaped lists as x-y pairs.\n",
    "        :param xlabel: Label for the x-axis.\n",
    "        :param ylabel: Label for the y-axis.\n",
    "        :param title: Title of the graph.\n",
    "        :param logx: If True, use logarithmic scale for the x-axis.\n",
    "        :param logy: If True, use logarithmic scale for the y-axis.\n",
    "        :param height: Height of the graph display.\n",
    "        :param width: Width of the graph display. If None, uses maximal width.\n",
    "        \"\"\"\n",
    "    \n",
    "        assert running_in_jupyter_notebook(), 'line_graph_via_bokeh is meant to be used in a notebook.'\n",
    "    \n",
    "        # Initialize Bokeh and import necessary modules\n",
    "        _initialize_bokeh()\n",
    "        import bokeh\n",
    "        from bokeh.plotting import figure, show\n",
    "        from bokeh.io import curdoc, output_notebook\n",
    "        from bokeh.themes import built_in_themes\n",
    "        from bokeh.palettes import Category10  # Import a built-in palette\n",
    "    \n",
    "        # Set up figure with specified parameters\n",
    "        fig_kwargs = {\n",
    "            'tools': 'pan,wheel_zoom,box_zoom,reset,hover,crosshair',\n",
    "            'height': height,\n",
    "            'x_axis_type': 'log' if logx else 'linear',\n",
    "            'y_axis_type': 'log' if logy else 'linear',\n",
    "            'x_axis_label': xlabel,\n",
    "            'y_axis_label': ylabel,\n",
    "            'title': title,\n",
    "            'sizing_mode': 'stretch_width' if width is None else None\n",
    "        }\n",
    "    \n",
    "        if width is not None:\n",
    "            fig_kwargs['width'] = width\n",
    "    \n",
    "        fig = figure(**fig_kwargs)\n",
    "    \n",
    "        # Function to process each dataset\n",
    "        def process_dataset(label, dataset, color):\n",
    "            x = list(range(len(dataset)))\n",
    "            y = dataset\n",
    "            fig.line(x, y, line_width=2, legend_label=str(label), color=color)\n",
    "    \n",
    "        # Determine the number of graphs and select a color palette\n",
    "        num_graphs = len(values) if isinstance(values, dict) else 1\n",
    "        palette = Category10[max(3, min(10, num_graphs))]  # Adjust the palette size based on number of graphs\n",
    "    \n",
    "        # Process values for line graphs\n",
    "        if isinstance(values, dict):\n",
    "            for (label, data), color in zip(values.items(), palette):\n",
    "                process_dataset(label, data, color)\n",
    "        else:\n",
    "            process_dataset(\"Data\", values, palette[0])\n",
    "    \n",
    "        # Apply dark theme and show the figure\n",
    "        curdoc().theme = 'dark_minimal'\n",
    "        show(fig)\n",
    "    \n",
    "    \n",
    "    from rp.r import _initialize_bokeh\n",
    "    \n",
    "    lt=rp.list_transpose([x['losses'] for x in logger_losses])\n",
    "    # for l in lt:\n",
    "        # line_graph_via_bokeh(l)\n",
    "    if not HEADLESS:\n",
    "        rp.line_graph_via_bokeh({str(i):lt[i] for i in range(len(lt))},logy=True)\n",
    "  except Exception as e:\n",
    "    rp.print_stack_trace(e)\n",
    "    rp.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python diffilu",
   "language": "python",
   "name": "diffilu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
