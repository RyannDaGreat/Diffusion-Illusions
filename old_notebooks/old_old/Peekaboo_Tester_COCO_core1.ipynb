{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Notebook Core Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_split=0 #Which notebook core is this?\n",
    "num_splits=3 #How many notebooks are running? \n",
    "device_num=0 #Which GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rp\n",
    "from icecream import ic\n",
    "from easydict import EasyDict\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestSample:\n",
    "    def __init__(self, image, prompt:str, path:str, name:str):\n",
    "        self.path=rp.get_absolute_path(path)\n",
    "        self.image=image\n",
    "        self.prompt=prompt\n",
    "        self.name=name\n",
    "    \n",
    "    def copy(self):\n",
    "        return copy.copy(self)\n",
    "    \n",
    "    def display(self):\n",
    "        print(self.prompt)\n",
    "        print(self.path)\n",
    "        rp.display_image(self.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CroppedCocoDataset:\n",
    "    \n",
    "    def __init__(self, samples=None, prompt_replacements:dict={}):\n",
    "        \n",
    "        #Xiang made this dataset\n",
    "        dataset_dir='/nfs/ws1/datasets/RefCOCO'\n",
    "        self.dataset_dir = dataset_dir\n",
    "        \n",
    "        if samples is None:\n",
    "            with rp.SetCurrentDirectoryTemporarily(dataset_dir):\n",
    "#                 # image_names=rp.text_file_to_string('refcoco_files.txt').strip().splitlines()\n",
    "#                 image_names=rp.get_all_image_files(relative=True)\n",
    "#                 #It has a bunch of lines that look like '2008_003885\\n2008_004212\\n2008_004612\\n2008_004621' etc\n",
    "#                 image_paths=image_names#['cropped-'+x+'.jpg' for x in image_names]\n",
    "#                 #These files should exist in the current directory\n",
    "#                 images=rp.load_images(image_paths, use_cache=True, show_progress=True)\n",
    "\n",
    "#                 assert all(rp.is_image_file(x) for x in image_paths)\n",
    "\n",
    "                #Get the prompts for every image\n",
    "                lines=rp.text_file_to_string('cropped.txt').strip().splitlines()\n",
    "                print(rp.line_join(lines[:5]))\n",
    "                #It has a bunch of lines that look like '2010_000241 bird\\n2010_000342 bicycle\\n2010_000628 car' etc\n",
    "                prompts    =[x.split(maxsplit=1)[1] for x in lines]\n",
    "                image_names=[x.split(maxsplit=1)[0] for x in lines]\n",
    "                # prompts={image_name:prompt for image_name,prompt in zip(image_names,prompts)}\n",
    "                image_paths=[rp.get_absolute_path(x) for x in image_names]\n",
    "                images=rp.load_images(image_paths, use_cache=True, show_progress=True)\n",
    "                \n",
    "\n",
    "                samples=[TestSample(image,prompt,path,name) for image,prompt,path,name in zip(images,prompts,image_paths,image_names)]\n",
    "\n",
    "        self.samples = samples\n",
    "        \n",
    "    @property\n",
    "    def images(self): return [s.image for s in self.samples]\n",
    "        \n",
    "    @property\n",
    "    def prompts(self): return [s.prompt for s in self.samples]\n",
    "\n",
    "    @property\n",
    "    def names(self): return [s.name for s in self.samples]\n",
    "\n",
    "    @property\n",
    "    def image_paths(self): return [s.image_path for s in self.samples]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        output = self.samples[index]\n",
    "        if isinstance(index, int):\n",
    "            return output\n",
    "        elif isinstance(index, slice):\n",
    "            output = type(self)(output)\n",
    "        return output\n",
    "            \n",
    "    def split(self, num_divisions, division_index):\n",
    "        \"\"\"\n",
    "        Split the dataset into num_divisions parts and return the division_index part.\n",
    "        \n",
    "        num_divisions: An integer representing the number of equal parts to divide the dataset into.\n",
    "        division_index: An integer representing the 0-indexed part to return.\n",
    "        \"\"\"\n",
    "        division_size = len(self) // num_divisions\n",
    "        start_index = division_size * division_index\n",
    "        end_index = start_index + division_size\n",
    "        if division_index == num_divisions - 1:\n",
    "            end_index = len(self)\n",
    "        return self[start_index:end_index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.samples)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'CroppedCocoDataset(len={len(self)})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=cropped_ref_voc_dataset.split(num_splits,num_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_coco_dataset=CroppedCocoDataset()\n",
    "data=cropped_coco_dataset.split(num_splits,num_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set(cropped_coco_dataset.prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[3:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.random_element(data).display()\n",
    "rp.random_element(data).display()\n",
    "rp.random_element(data).display()\n",
    "rp.random_element(data).display()\n",
    "rp.random_element(data).display()\n",
    "rp.random_element(data).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peekaboo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import source.stable_diffusion as sd\n",
    "if 's' not in dir():\n",
    "    s=sd.StableDiffusion(device=device_num) #Initialize the singleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ujL4Q8IHPhm0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import rp\n",
    "import source.peekaboo as peekaboo\n",
    "from source.peekaboo import run_peekaboo\n",
    "from source.clip import get_clip_logits\n",
    "from source.stable_diffusion_labels import get_mean_embedding, BaseLabel, SimpleLabel, MeanLabel\n",
    "import torch\n",
    "torch.cuda.set_device(device_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9Sgqq2J32Qzs",
    "outputId": "eee9073d-e09f-49ca-ca1a-5bb8b8d5e19c"
   },
   "outputs": [],
   "source": [
    "#Mario vs Luigi Part 1\n",
    "results_collection=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clip_logits_per_image(prompt, images):\n",
    "    return [get_clip_logits(image, [prompt])[0] for image in images]\n",
    "\n",
    "def random_colors(length=100):\n",
    "    return [rp.random_rgb_float_color() for _ in range(length)]\n",
    "\n",
    "def get_score(foreground, alpha, prompt:str, colors:list):\n",
    "    \n",
    "    alpha=alpha>.5\n",
    "    rp.display_image(rp.blend_images(rp.random_rgb_float_color(),rp.cv_resize_image(foreground,rp.get_image_dimensions(alpha)),alpha))\n",
    "    alpha=rp.cv_dilate(alpha,5,circular=True)\n",
    "    \n",
    "    assert rp.is_image(foreground) and rp.is_image(alpha)\n",
    "    images = [rp.blend_images(foreground, color, alpha) for color in colors]\n",
    "    scores = get_clip_logits_per_image(prompt, images)\n",
    "    score = rp.mean(scores)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranked_results(results):\n",
    "    colors = random_colors()\n",
    "    def score(result):\n",
    "        output = get_score(foreground = result.image,\n",
    "                         alpha = result.alphas[0],\n",
    "                         prompt = result.p_name,\n",
    "                         colors = colors,\n",
    "                        )\n",
    "        print(output)\n",
    "        return output\n",
    "    scores = list(map(score,results))\n",
    "    scores, results = rp.sync_sort(scores, results)\n",
    "    \n",
    "    #First is best\n",
    "    scores, results = scores[::-1], results[::-1]\n",
    "    \n",
    "    return scores, results\n",
    "\n",
    "def display_ranked_results(scores, results):\n",
    "    for score, result in zip(scores, results):\n",
    "        rp.display_image(\n",
    "            rp.labeled_image(\n",
    "                rp.horizontally_concatenated_images(\n",
    "                    rp.cv_resize_image(result.image, (256, 256)), result.alphas[0]\n",
    "                ),\n",
    "                \"%s : %f\" % (result.p_name, score),\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbnails=[]\n",
    "def get_result_thumbnail(results):\n",
    "    alpha, image = results.alphas[0], results.image\n",
    "    height = width = 512 \n",
    "    image = rp.cv_resize_image(image, (height, width))\n",
    "    alpha = rp.cv_resize_image(alpha, (height, width),interp='nearest')\n",
    "    method = \" + \".join(\n",
    "        [\n",
    "            *([\"CLIP\"] if results.clip_coef else []),\n",
    "            *([\"StableDreamLoss\"] if results.use_stable_dream_loss else []),\n",
    "        ]\n",
    "    )\n",
    "    path = rp.get_relative_path(results.output_folder)\n",
    "    name = results.p_name\n",
    "    settings=[\n",
    "        'representation',\n",
    "        'LEARNING_RATE',\n",
    "        'NUM_ITER',\n",
    "        'GRAVITY',\n",
    "        'clip_coef',\n",
    "        'use_stable_dream_loss',\n",
    "        'GUIDANCE_SCALE',\n",
    "        'min_step',\n",
    "        'max_step',\n",
    "        'clip_coef',\n",
    "    ]\n",
    "    settings=[x+': '+str(results[x]) for x in settings]\n",
    "    \n",
    "    \n",
    "    text=rp.line_join([name, ' ', method, ' ', path, '', 'Settings:',*settings])\n",
    "    text=rp.wrap_string_to_width(text,60)\n",
    "    text = rp.cv_text_to_image(text,monospace=False)\n",
    "    text = rp.resize_image_to_fit(text, height, width)\n",
    "    image=rp.horizontally_concatenated_images(image,alpha,text)\n",
    "    \n",
    "    out_dir='thumbnails_data8'\n",
    "    rp.make_directory(out_dir)\n",
    "    out_name='%s ____ %s ____ %i.png'%(method, name,len(rp.get_all_files(out_dir)))\n",
    "    out_path=rp.path_join(out_dir,out_name)\n",
    "    rp.save_image(image,out_path)\n",
    "    \n",
    "    thumbnails.append(image)\n",
    "    rp.display_image(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_input_data = [\n",
    "    [ [x.prompt], [x.path] , x] for x in data.samples\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9Sgqq2J32Qzs",
    "outputId": "eee9073d-e09f-49ca-ca1a-5bb8b8d5e19c"
   },
   "outputs": [],
   "source": [
    "experiment_setting_presets = {\n",
    "    'clip_raster_bilateral':dict(\n",
    "        representation=\"raster bilateral\",\n",
    "        LEARNING_RATE=1e-0,\n",
    "        NUM_ITER=100,\n",
    "        GRAVITY=0.05,\n",
    "        clip_coef=500,\n",
    "        use_stable_dream_loss=False,\n",
    "    ),\n",
    "    'raster_bilateral':dict( #This one is also good!\n",
    "        representation=\"raster bilateral\",\n",
    "        LEARNING_RATE=1e-0,\n",
    "        GUIDANCE_SCALE=200,\n",
    "        NUM_ITER=100,\n",
    "        GRAVITY=0.05,\n",
    "        # min_step=10,\n",
    "        # max_step=600,\n",
    "    ),\n",
    "    # dict(\n",
    "    #     representation=\"raster bilateral\",\n",
    "    #     LEARNING_RATE=1e-0,\n",
    "    #     GUIDANCE_SCALE=200,\n",
    "    #     # NUM_ITER=500,\n",
    "    #     GRAVITY=0.05,\n",
    "    #     min_step=200,\n",
    "    #     max_step=400,\n",
    "    # ),\n",
    "    # dict(\n",
    "    #     representation=\"raster bilateral\",\n",
    "    #     LEARNING_RATE=1e-0,\n",
    "    #     # NUM_ITER=500,\n",
    "    #     GRAVITY=0.05,\n",
    "    #     clip_coef=500,\n",
    "    #     use_stable_dream_loss=True,\n",
    "    #     GUIDANCE_SCALE=200,\n",
    "    #     min_step=10,\n",
    "    #     max_step=600,\n",
    "    # ),\n",
    "    # dict(NUM_ITER=500),\n",
    "    # 'pure_fourier':dict(representation=\"fourier\"),\n",
    "    # 'default':dict(),\n",
    "    # 'pure_raster':dict(representation=\"raster\", LEARNING_RATE=1, GUIDANCE_SCALE=200,GRAVITY=.1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9Sgqq2J32Qzs",
    "outputId": "eee9073d-e09f-49ca-ca1a-5bb8b8d5e19c"
   },
   "outputs": [],
   "source": [
    "# experiment_setting_presets=[dict()]\n",
    "\n",
    "things_to_try=[]\n",
    "\n",
    "for prompts, urls, sample in rp.shuffled(experiment_input_data):\n",
    "    for prompt in prompts:\n",
    "        for url in urls:\n",
    "            things_to_try.append([prompt,url,sample])\n",
    "\n",
    "i=0\n",
    "while True:\n",
    "    # things_to_try=rp.shuffled(things_to_try)\n",
    "    for prompt,url,sample in things_to_try:\n",
    "        sample_name=sample.name\n",
    "        for preset_name,preset in experiment_setting_presets.items():\n",
    "            i+=1\n",
    "            rp.fansi_print('EXPERIMENT NUMBER: %i'%i,'green','bold')\n",
    "            rp.fansi_print(preset_name,'green','bold')\n",
    "            rp.fansi_print(sample_name,'green','bold')\n",
    "\n",
    "            rp.ic(prompt,url,preset)\n",
    "\n",
    "            results = run_peekaboo(\n",
    "                name=sample_name+'.'+prompt+'.'+preset_name,\n",
    "                label=SimpleLabel(prompt),\n",
    "                image=url,\n",
    "                **preset,\n",
    "                output_folder_name='peekaboo_results_coco_nocrop'\n",
    "            )\n",
    "\n",
    "            get_result_thumbnail(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
